# OCI AI Portfolio - SÄ±nav HazÄ±rlÄ±k Rehberi
## Oracle Cloud Infrastructure AI Foundations SertifikasÄ±
**HazÄ±rlayan:** Claude | **Tarih:** 6 Ocak 2026

---

## ğŸ“‹ Ä°Ã§indekiler

1. OCI AI Services
2. OCI ML Services (Data Science)
3. GPU & AI Infrastructure
4. RDMA & Supercluster
5. Responsible AI
6. SÄ±nav Stratejisi

---

## 1. OCI AI SERVICES

### 1.1 OCI AI Services (Genel)
* **Basit TanÄ±m:** Oracle'Ä±n hazÄ±r yapay zeka oyuncaklarÄ± - kodlama bilmeden resim, metin ve ses iÅŸleyebilirsin.
* **Teknik TanÄ±m:** Prebuilt machine learning modelleri iÃ§eren, custom training desteÄŸi sunan, infrastructure yÃ¶netimi gerektirmeyen, API tabanlÄ± cloud servisleri.

**Ne Zaman Kullan:**
* Data science ekibin yok ama ML/AI yetenekleri lazÄ±m
* HÄ±zlÄ± prototipleme gerekiyor
* Infrastructure yÃ¶netimi istemiyorsun

**Ã–rnek:** E-ticaret ÅŸirketi mÃ¼ÅŸteri yorumlarÄ±nÄ± analiz etmek istiyor ama ML ekibi yok. OCI Language Service kullanarak sentiment analysis yapabilir.
> **SÄ±nav Ä°pucu:** "prebuilt models", "no infrastructure management", "API-based"

### 1.2 OCI Language Service
* **Basit TanÄ±m:** Metinleri okuyan ve anlam Ã§Ä±karan akÄ±llÄ± okuyucu - mutlu mu Ã¼zgÃ¼n mÃ¼, hangi dilde, Ã¶nemli kelimeler neler anlÄ±yor.
* **Teknik TanÄ±m:** NLP servisi. Sentiment analysis, named entity recognition, PII detection, text translation.

**Ã–zellikler:**
* **Pretrained Models:** Language detection, sentiment analysis, key phrase extraction, text classification, NER, PII detection
* **Custom Models:** Domain-specific NER ve text classification
* **Translation:** Neural machine translation

**Ne Zaman Kullan:**
* MÃ¼ÅŸteri yorumlarÄ± sentiment analizi
* Ã‡ok dilli dÃ¶kÃ¼manlarda dil tespiti
* PII verilerini otomatik tespit
* Otomatik Ã§eviri

**Ne Zaman Kullanma:**
* Real-time konuÅŸma Ã§evirisi (Speech kullan)
* GÃ¶rÃ¼ntÃ¼deki metni okuma (Vision OCR kullan)

**Ã–rnek:** Banka KVKK uyumluluÄŸu iÃ§in binlerce mÃ¼ÅŸteri mailinde TC kimlik numarasÄ±, telefon gibi PII verilerini otomatik tespit edip maskeliyor.
> **SÄ±nav Ä°pucu:** "sentiment analysis", "text analysis", "PII detection", "named entity recognition"

### 1.3 OCI Vision Service
* **Basit TanÄ±m:** Resimlere bakÄ±p "bu bir kedi, ÅŸurada araba var" diyen gÃ¶zlÃ¼k. Resimlerdeki yazÄ±larÄ± da okuyabiliyor.
* **Teknik TanÄ±m:** Computer vision servisi. Object detection, image classification, OCR yetenekli. Bounding box koordinatlarÄ± saÄŸlar.

**Ã–zellikler:**
* **Pretrained Models:** Object detection, image classification, OCR
* **Custom Models:** Custom object detection, custom image classification

**Ne Zaman Kullan:**
* Resimlerdeki objeleri detect/classify
* GÃ¶rÃ¼ntÃ¼lerdeki metni extract (OCR)
* Custom object detection (fabrikada hatalÄ± Ã¼rÃ¼n tespiti)

**Ne Zaman Kullanma:**
* Strukturlu dÃ¶kÃ¼manlar (fatura, form) â†’ **Document Understanding kullan**
* Sadece metin iÅŸleme â†’ **Language kullan**

**Ã–rnek:** Retail maÄŸazasÄ± gÃ¼venlik kameralarÄ±ndan "maÄŸazada kaÃ§ mÃ¼ÅŸteri var, hangi raflarda yoÄŸunluk var" tespit etmek iÃ§in custom object detection kullanÄ±yor.
> **SÄ±nav Ä°pucu:** "image classification", "object detection", "OCR on images", "bounding box"

### 1.4 OCI Speech Service
* **Basit TanÄ±m:** KonuÅŸmalarÄ± dinleyip yazÄ±ya dÃ¶ken sekreter. Ses dosyasÄ± verirsin, metin olarak alÄ±rsÄ±n.
* **Teknik TanÄ±m:** Speech-to-text servisi. Audio/media dosyalarÄ±nÄ± highly accurate text transcription'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. JSON ve SRT formatÄ±nda output.

**Ne Zaman Kullan:**
* Podcast, webinar, toplantÄ± kayÄ±tlarÄ±nÄ± metne Ã§evirme
* Call center kayÄ±tlarÄ±nÄ± analiz
* Video altyazÄ±sÄ± oluÅŸturma

**Ne Zaman Kullanma:**
* Metin zaten var, analiz edeceksin (Language kullan)
* GÃ¶rÃ¼ntÃ¼/video var ama ses yok (Vision kullan)

**Ã–rnek:** Hukuk firmasÄ± mahkeme duruÅŸma kayÄ±tlarÄ±nÄ± Speech Service ile metne Ã§eviriyor, sonra Language Service ile Ã¶nemli entity'leri Ã§Ä±karÄ±yor.
> **SÄ±nav Ä°pucu:** "speech-to-text", "media files", "transcription", "audio to text"

### 1.5 OCI Document Understanding
* **Basit TanÄ±m:** Fatura, pasaport gibi dÃ¶kÃ¼manlarÄ± okuyan akÄ±llÄ± tarayÄ±cÄ±. Hem metni hem tablolarÄ± hem de hangi tip dÃ¶kuman olduÄŸunu anlÄ±yor.
* **Teknik TanÄ±m:** OCR ve AI tabanlÄ± document processing. Text extraction, key-value extraction, table extraction, document classification. Word/line level bounding box.

**Ã–zellikler:**
* **Text Extraction:** Word ve line level text + coordinates
* **Key-Value Extraction:** Fatura, makbuz, pasaport, ehliyet iÃ§in predefined pairs
* **Table Extraction:** Row-column iliÅŸkisi korunarak tabular format
* **Document Classification:** DÃ¶kuman tipini otomatik classify

**Ne Zaman Kullan:**
* Fatura, makbuz, pasaport, ehliyet iÅŸleme
* Tablo formatÄ±ndaki datalarÄ± extract
* DÃ¶kuman tipini otomatik classify
* Batch processing (Ã§ok sayÄ±da belge)

**Ne Zaman Kullanma:**
* Sadece sade metin analizi (Language kullan)
* Resimde genel obje tespiti (Vision kullan)

**Ã–rnek:** Muhasebe firmasÄ± gÃ¼nde yÃ¼zlerce fatura alÄ±yor. Document Understanding ile belge tipini classify ediyor, key-value extraction ile "Fatura No, Tarih, Toplam Tutar" Ã§Ä±karÄ±p ERP'ye aktarÄ±yor.
> **SÄ±nav Ä°pucu:** "key-value extraction", "table extraction", "document classification", "invoice/receipt"

### 1.6 Oracle Digital Assistant
* **Basit TanÄ±m:** Seninle konuÅŸabilen akÄ±llÄ± asistan. "SipariÅŸimi nerede?" diye sorarsÄ±n, o anlar ve doÄŸru yere yÃ¶nlendirir.
* **Teknik TanÄ±m:** Natural language conversation ile kullanÄ±cÄ± isteklerini anlayan, route eden, skills arasÄ±nda orchestration yapan chatbot platformu.

**Ã–zellikler:**
* Skills routing
* Intent recognition
* Dialogue management
* Interruption handling
* Disambiguation

**Ne Zaman Kullan:**
* MÃ¼ÅŸteri hizmetleri chatbot
* Multiple skills/domain arasÄ±nda yÃ¶nlendirme
* Natural language interface
* Conversational AI ile self-service

**Ã–rnek:** E-ticaret sitesi mÃ¼ÅŸterilerin "sipariÅŸim nerede?", "Ã¼rÃ¼n iade nasÄ±l?", "indirim kodu" gibi farklÄ± skill gerektiren sorularÄ± Digital Assistant ile yÃ¶netiyor.
> **SÄ±nav Ä°pucu:** "chatbot", "natural language conversation", "skills routing", "conversational AI"

#### ğŸ¯ AI Services HÄ±zlÄ± Karar Tablosu

| Soruda Bu Var | Bu Servisi SeÃ§ |
| :--- | :--- |
| sentiment, text analysis, PII | **Language** |
| image, object detection, OCR on photo | **Vision** |
| audio, speech, transcription | **Speech** |
| invoice, receipt, table extraction | **Document Understanding** |
| chatbot, conversation, skills | **Digital Assistant** |

**Kritik AyrÄ±m:**
* **Vision OCR** = Resimlerdeki metin (fotoÄŸraf, billboard)
* **Document Understanding OCR** = YapÄ±landÄ±rÄ±lmÄ±ÅŸ belgeler (fatura, form)

---

## 2. OCI ML SERVICES (DATA SCIENCE)

### 2.1 OCI Data Science Service
* **Basit TanÄ±m:** Data scientist'ler iÃ§in hazÄ±r oyun alanÄ± - kod yazarsÄ±n, modeli eÄŸitirsin, yayÄ±nlarsÄ±n; server kurulum derdin yok.
* **Teknik TanÄ±m:** Full ML lifecycle platformu. Python ve open-source destekli, managed infrastructure, JupyterLab interface.

**ÃœÃ§ Temel Ä°lke:**
1.  **Accelerated:** Individual data scientist productivity
2.  **Collaborative:** Team sharing, reduce duplicate work
3.  **Enterprise Grade:** OCI security integration, fully managed

**Ne Zaman Kullan:**
* Custom ML modelleri geliÅŸtirme
* Data science ekibi collaborative Ã§alÄ±ÅŸacak
* Python/open-source kullanÄ±m
* End-to-end ML lifecycle

**Ne Zaman Kullanma:**
* HazÄ±r AI servisleri yeterli
* Data science yetkinliÄŸi yok

**Ã–rnek:** Telekom ÅŸirketi churn prediction iÃ§in custom model geliÅŸtiriyor. JupyterLab'de geliÅŸtirip Model Catalog'da paylaÅŸÄ±yor, HTTP endpoint olarak deploy ediyor.
> **SÄ±nav Ä°pucu:** "JupyterLab", "full ML lifecycle", "custom model", "collaborative", "Python"

### 2.2 Projects
* **Basit TanÄ±m:** Ana klasÃ¶r - tÃ¼m notebook'larÄ±n, modellerin, job'larÄ±n toplandÄ±ÄŸÄ± organizasyon kutusu.
* **Teknik TanÄ±m:** Data science assets'leri organize eden container. Notebook sessions, jobs, pipelines, models, deployments iÃ§erir.

**Ne Zaman Kullan:**
* Ekip halinde Ã§alÄ±ÅŸma
* FarklÄ± ML projelerini izole tutma
* Asset management

**Ã–rnek:** "Fraud Detection", "Credit Scoring", "Customer Segmentation" iÃ§in ayrÄ± projeler.
> **SÄ±nav Ä°pucu:** "project", "container", "workspace", "organize"

### 2.3 Notebook Sessions
* **Basit TanÄ±m:** Data scientist'in kod yazdÄ±ÄŸÄ± defter - iÃ§inde Python kÃ¼tÃ¼phaneleri hazÄ±r, istediÄŸin bilgisayar gÃ¼cÃ¼nÃ¼ seÃ§ersin.
* **Teknik TanÄ±m:** JupyterLab environment. CPU/GPU compute shape seÃ§imi, AMD/Intel/Other, managed infrastructure, no manual provisioning.

**Configuration SeÃ§enekleri:**
* Compute shape (CPU/GPU)
* Shape series (AMD/Intel)
* Number of CPUs
* Memory amount
* Block storage
* Networking
* Endpoint type

**Ne Zaman Kullan:**
* Interactive ML development
* Data exploration
* Model training & experimentation

**Ne Zaman Kullanma:**
* Production deployment (Model Deployment kullan)
* Scheduled tasks (Jobs kullan)

**Ã–rnek:** Data scientist Intel shape ile data exploration baÅŸlayÄ±p GPU shape'e switch ederek training yapÄ±yor.
> **SÄ±nav Ä°pucu:** "JupyterLab", "interactive", "CPU/GPU selection", "managed infrastructure"

### 2.4 Conda Environments
* **Basit TanÄ±m:** HazÄ±r kÃ¼tÃ¼phane paketi - "ML iÃ§in gerekli 50 kÃ¼tÃ¼phane" gibi, tek komutla yÃ¼klersin.
* **Teknik TanÄ±m:** Prepackaged environment with use-case specific libraries. Environment Explorer'da gÃ¶rÃ¼nÃ¼r, Terminal'de install edilir, kernel olarak seÃ§ilir.

**Workflow:**
1.  Environment Explorer â†’ Browse
2.  Copy install command
3.  Terminal â†’ Paste & run
4.  Refresh
5.  Select kernel

**Ne Zaman Kullan:**
* Specific ML framework gerekiyor
* Use-case specific packages (NLP, CV)
* Dependency management

**Ã–rnek:** NLP projesi iÃ§in "NLP" conda environment install ediliyor, NLTK, spaCy, transformers hazÄ±r geliyor.
> **SÄ±nav Ä°pucu:** "Conda environment", "prepackaged", "Environment Explorer", "kernel"

### 2.5 ADS SDK (Accelerated Data Science)
* **Basit TanÄ±m:** Oracle'Ä±n data scientist'lere verdiÄŸi hazÄ±r araÃ§ kutusu - sÄ±k yapÄ±lan iÅŸler iÃ§in kÄ±sa yollar.
* **Teknik TanÄ±m:** Oracle'Ä±n Python library'si. Workflow'u simplify/automate eder: data connection, exploration, AutoML, model explanation.

**Ã–zellikler:**
* AutoML
* Model explanation
* OCI Object Storage interface
* Workflow automation

**ADS Workflow (6 AdÄ±m):**
1.  **INITIATE** â†’ Model object oluÅŸtur
2.  **PREPARE** â†’ `.prepare()` - Artifacts generate
3.  **VERIFY** â†’ `.verify()` - Test without deploy
4.  **SAVE** â†’ `.save()` - Model Catalog'a kaydet
5.  **DEPLOY** â†’ `.deploy()` - REST endpoint oluÅŸtur
6.  **PREDICT** â†’ `.predict()` - Inference al

*Status Tracking:* `.summary_status()` - Her adÄ±mÄ±n durumunu gÃ¶sterir

**2.5.1 prepare() Method**
* **Ne Yapar:** Model artifacts'larÄ± otomatik generate eder (`score.py`, `runtime.yaml`, serialized model)
* **Ne Zaman Kullan:** Model deployment hazÄ±rlÄ±ÄŸÄ±
* **Ã–rnek:** `model.prepare()` â†’ TÃ¼m deployment dosyalarÄ± otomatik oluÅŸur
* **SÄ±nav Ä°pucu:** "generate artifacts", "automation", "no configuration"

**2.5.2 verify() Method**
* **Ne Yapar:** Deployment'Ä± simulate eder, gerÃ§ek deploy etmeden test eder
* **Ne Zaman Kullan:** Pre-deployment testing, artifact validation
* **Ã–rnek:** `model.verify(test_data)` â†’ Local inference, hata varsa burada yakala
* **SÄ±nav Ä°pucu:** "simulate deployment", "test without deploy", "validate"

**2.5.3 save() Method**
* **Ne Yapar:** Modeli Model Catalog'a kaydeder
* **Ne Zaman Kullan:** Model versioning, team collaboration, artifact preservation
* **Ã–rnek:** `model.save()` â†’ Model Catalog'da gÃ¶rÃ¼nÃ¼r, paylaÅŸÄ±labilir
* **SÄ±nav Ä°pucu:** "Model Catalog", "versioning", "sharing", "catalog entry"

**2.5.4 deploy() Method**
* **Ne Yapar:** Modeli REST endpoint olarak deploy eder
* **Ne Zaman Kullan:** Production model serving, real-time inference
* **Ã–rnek:** `model.deploy()` â†’ HTTP endpoint oluÅŸur
* **SÄ±nav Ä°pucu:** "REST endpoint", "HTTP API", "real-time serving", "production"

**2.5.5 predict() Method**
* **Ne Yapar:** Deployed endpoint'ten prediction alÄ±r
* **Ne Zaman Kullan:** Testing deployed model, production inference
* **Ã–rnek:** `model.predict(new_data)` â†’ Endpoint'e request, result dÃ¶ner
* **SÄ±nav Ä°pucu:** "invoke endpoint", "generate prediction", "deployed model"

### 2.6 Model Catalog
* **Basit TanÄ±m:** Modellerin kÃ¼tÃ¼phanesi - eÄŸittiÄŸin modelleri raftaki gibi saklar, takÄ±mla paylaÅŸÄ±rsÄ±n.
* **Teknik TanÄ±m:** Centralized managed repository. Model metadata, provenance (Git info, source script), versioning. Cross-team sharing.

**Ne Zaman Kullan:**
* Model versioning & tracking
* Team collaboration
* Auditability & compliance
* Reproducibility

**Ã–rnek:** ML ekibi ayda 20 model versiyonu deniyor. Her version metadata ile saklanÄ±yor, 6 ay sonra "o zamanki en iyi model"i geri yÃ¼kleyebiliyorlar.
> **SÄ±nav Ä°pucu:** "centralized repository", "versioning", "provenance", "metadata", "sharing"

### 2.7 Model Deployments
* **Basit TanÄ±m:** EÄŸitilmiÅŸ modeli internete aÃ§an dÃ¼ÄŸme - model artÄ±k web adresi olur, isteklere cevap verir.
* **Teknik TanÄ±m:** Model Catalog'daki modelleri HTTP API endpoints olarak deploy eder. Real-time prediction serving, managed infrastructure.

**Ne Zaman Kullan:**
* Real-time prediction
* Model production'a alma
* HTTP API endpoint
* Scalable inference

**Ne Zaman Kullanma:**
* Batch prediction (Job kullan)
* Offline analysis

**Ã–rnek:** E-ticaret sitesi recommendation model'i HTTP endpoint olarak deploy etmiÅŸ, web app her sepet deÄŸiÅŸiminde request atÄ±yor.
> **SÄ±nav Ä°pucu:** "HTTP endpoint", "API", "real-time prediction", "production deployment"

### 2.8 Jobs
* **Basit TanÄ±m:** Tekrarlayan robot iÅŸÃ§i - "her gÃ¼n ÅŸu modeli yeniden eÄŸit" dersen otomatik yapar.
* **Teknik TanÄ±m:** Repeatable ML tasks'Ä± fully managed infrastructure'da define ve run eder. Scheduled/on-demand execution.

**Ne Zaman Kullan:**
* Scheduled model retraining
* Batch inference
* Automated data pipelines
* Production-grade scheduled tasks

**Ne Zaman Kullanma:**
* Interactive development (Notebook kullan)
* Real-time serving (Model Deployment kullan)

**Ã–rnek:** Retail ÅŸirketi her Pazar gecesi sales data ile demand forecasting modelini retrain ediyor.
> **SÄ±nav Ä°pucu:** "repeatable tasks", "scheduled execution", "batch processing", "automated"

#### ğŸ¯ Data Science HÄ±zlÄ± Karar Tablosu

| Soruda Bu Var | Bu Component'i SeÃ§ |
| :--- | :--- |
| JupyterLab, interactive, kod yazma | **Notebook Sessions** |
| organize, team workspace | **Projects** |
| model saklama, versioning | **Model Catalog** |
| HTTP endpoint, real-time prediction | **Model Deployments** |
| scheduled, repeatable, batch | **Jobs** |
| package management, environment | **Conda** |
| AutoML, Oracle library, simplify | **ADS SDK** |

**Kritik AyrÄ±mlar:**
* **Notebook Sessions** = Interactive development
* **Jobs** = Automated, scheduled tasks
* **Model Catalog** = Storage & versioning
* **Model Deployment** = Production serving

---

## 3. GPU & AI INFRASTRUCTURE

### 3.1 GPU (Graphics Processing Unit)
* **Basit TanÄ±m:** AynÄ± anda binlerce hesap yapabilen sÃ¼per hÄ±zlÄ± hesap makinesi - CPU tek kiÅŸi gibi, GPU binlerce kiÅŸi gibi paralel Ã§alÄ±ÅŸÄ±r.
* **Teknik TanÄ±m:** Thousands of lightweight cores ile parallel computing. Deep learning frameworks (TensorFlow, PyTorch) ile entegre. High throughput.

**Neden GPU:**
* Parallel computing (thousands of cores)
* Deep learning optimization
* Batch processing
* Simultaneous requests serving
* High throughput

**Ne Zaman Kullan:**
* Model training (deep learning)
* Large-scale inference
* Transformer models, LLM
* High throughput kritik

**Ne Zaman Kullanma:**
* Simple tabular ML (CPU yeterli)
* Low-volume inference
* Budget constraint

**Ã–rnek:** LLM fine-tuning CPU ile gÃ¼nler sÃ¼rerken GPU cluster ile saatlere iniyor.
> **SÄ±nav Ä°pucu:** "parallel computing", "thousands of cores", "deep learning", "high throughput"

### 3.2 GPU Architecture Timeline

| Year | Architecture | GPU | Key Feature |
| :--- | :--- | :--- | :--- |
| 2020 | Ampere | **A100** | Tensor cores |
| 2022 | Hopper | **H100** | Transformer engine |
| 2024 | Hopper | **H200** | More memory |
| 2025 | Blackwell | **B200** | Large-scale AI |
| 2025 | Grace Blackwell | **GB200** | Superchip (2x CPU + GPU) |

### 3.3 NVIDIA A100 (Ampere)
* **Basit TanÄ±m:** 2020 model gÃ¼Ã§lÃ¼ GPU - "tensor core" denen Ã¶zel hesap birimleri var.
* **Teknik TanÄ±m:** Ampere architecture, 2020. Tensor cores ile fused multiply-accumulate operations single clock cycle'da.

**Ne Zaman Kullan:**
* Standard deep learning training
* Mid-scale AI workloads
* Cost-performance balance
> **SÄ±nav Ä°pucu:** "A100", "Ampere", "2020", "tensor cores"

### 3.4 NVIDIA H100 (Hopper)
* **Basit TanÄ±m:** 2022 model sÃ¼per GPU - Ã¶zellikle transformer modelleri iÃ§in Ã¶zel motor var.
* **Teknik TanÄ±m:** Hopper architecture, 2022. Dedicated transformer engine. A100'den daha geliÅŸmiÅŸ.

**Ne Zaman Kullan:**
* Transformer models (BERT, GPT, T5)
* LLM training & inference
* State-of-the-art deep learning
> **SÄ±nav Ä°pucu:** "H100", "Hopper", "2022", "transformer engine", "LLM"

### 3.5 NVIDIA H200
* **Basit TanÄ±m:** H100'Ã¼n abisi - aynÄ± ama daha Ã§ok hafÄ±zasÄ± var, bÃ¼yÃ¼k modeller iÃ§in ideal.
* **Teknik TanÄ±m:** 2024, H100 benzeri ama more memory. Memory-intensive LLM iÃ§in optimize.

**Ne Zaman Kullan:**
* Very large LLM (billions of parameters)
* Memory-intensive workloads
* H100'de memory bottleneck
> **SÄ±nav Ä°pucu:** "H200", "2024", "more memory", "large LLM"

### 3.6 NVIDIA B200 (Blackwell)
* **Basit TanÄ±m:** 2025 model en yeni nesil - Ã¶zellikle dev AI modelleri iÃ§in tasarlanmÄ±ÅŸ.
* **Teknik TanÄ±m:** Blackwell architecture, 2025. Large-scale AI models iÃ§in. H100'e gÃ¶re significant performance improvement.

**Ne Zaman Kullan:**
* Cutting-edge LLM projects
* Maximum performance
* State-of-the-art AI research
> **SÄ±nav Ä°pucu:** "B200", "Blackwell", "2025", "large-scale AI"

### 3.7 NVIDIA GB200 (Grace Blackwell Superchip)
* **Basit TanÄ±m:** SÃ¼per gÃ¼Ã§lÃ¼ combo - 2 Ã¶zel CPU + Blackwell GPU birleÅŸmiÅŸ, AI datacenterleri iÃ§in.
* **Teknik TanÄ±m:** 2x NVIDIA Grace CPU + Blackwell GPU unified system. HPC ve AI datacenter iÃ§in breakthrough processor.

**Ne Zaman Kullan:**
* Superclusters
* Extreme-scale AI workloads
* HPC + AI combined
* Datacenter-level infrastructure
> **SÄ±nav Ä°pucu:** "GB200", "Grace Blackwell", "superchip", "2x CPU", "unified"

### 3.8 NVIDIA L40 / L4
* **Basit TanÄ±m:** Orta sÄ±nÄ±f GPU - Ã§ok gÃ¼Ã§lÃ¼ olmasa da maliyetli deÄŸil, kÃ¼Ã§Ã¼k-orta iÅŸler iÃ§in yeterli.
* **Teknik TanÄ±m:** Small to medium use cases iÃ§in cost-effective GPU. Generally available.

**Ne Zaman Kullan:**
* Small to medium workloads
* Cost-optimization
* Inference workloads
* Dev/test environments
> **SÄ±nav Ä°pucu:** "L40", "L4", "cost-effective", "small/medium"

### 3.9 Performance KarÅŸÄ±laÅŸtÄ±rmasÄ±
* **H200** â†’ 4X performance of H100 superclusters
* **B200/GB200** â†’ Peak performance of H100 for AI workloads

### 3.10 OCI Data Science AI Quick Actions
* **Basit TanÄ±m:** HazÄ±r LLM'leri tek tuÅŸla GPU'ya deploy eden kolaylÄ±k - fine-tune etmek de mÃ¼mkÃ¼n.
* **Teknik TanÄ±m:** Popular LLM'leri GPU-powered instances'a deploy eder. Base models fine-tune edip custom deploy. vLLM, text-embedding inference destekler.

**Ne Zaman Kullan:**
* LLM'leri quickly deploy
* LLM fine-tuning
* GPU instances model serving

**Supported Containers:**
* vLLM
* Next generation inference
* Text-embedding inference

**Ã–rnek:** E-ticaret Llama-2'yi product data ile fine-tune edip H100 instance'da deploy ediyor.
> **SÄ±nav Ä°pucu:** "AI Quick Actions", "deploy LLM", "fine-tune", "vLLM", "GPU instances"

#### ğŸ¯ GPU HÄ±zlÄ± Karar Tablosu

| Soruda Bu Var | Bu GPU'yu SeÃ§ |
| :--- | :--- |
| Transformer, LLM, dedicated engine | **H100 (Hopper)** |
| More memory, large LLM, 2024 | **H200** |
| Latest, Blackwell, 2025 | **B200** |
| Superchip, unified CPU-GPU, HPC | **GB200** |
| Cost-effective, small/medium | **L40/L4** |
| Tensor cores, 2020 | **A100** |

---

## 4. RDMA & SUPERCLUSTER

### 4.1 RDMA (Remote Direct Memory Access)
* **Basit TanÄ±m:** CPU'yu aradan Ã§Ä±karÄ±p iki bilgisayarÄ±n direkt konuÅŸmasÄ±nÄ± saÄŸlayan sÃ¼per hÄ±zlÄ± yol.
* **Teknik TanÄ±m:** CPU bypass ederek machine-to-machine data transfer. Extremely low latency, high bandwidth, low CPU overhead.

**KullanÄ±m AlanlarÄ±:**
* GPU cluster communication
* Database services (ExaCS, Autonomous)
* HPC workloads

**Ne Zaman Kullan:**
* GPU distributed training
* Low latency kritik
* High bandwidth gerekiyor
* Database clusters

**Ã–rnek:** 1000 GPU distributed training yapÄ±yor. RDMA ile GPU'lar microsecond latency'de konuÅŸuyor, CPU overhead olmadan.
> **SÄ±nav Ä°pucu:** "bypass CPU", "low latency", "high bandwidth", "GPU communication"

### 4.2 RoCE (RDMA over Converged Ethernet)
* **Basit TanÄ±m:** RDMA'yÄ± normal Ethernet kablolarÄ± Ã¼zerinden Ã§alÄ±ÅŸtÄ±ran teknoloji.
* **Teknik TanÄ±m:** RDMA'yÄ± Ethernet fabric Ã¼zerinde enable eden protocol. OCI'Ä±n strategic bet. HPC, GPU, database workloads aynÄ± fabric'te.

**Ne Zaman Kullan:**
* Ethernet infrastructure var, RDMA benefits istiyorsun
* Multiple workload types aynÄ± fabric
* Converged network

**Ã–rnek:** OCI datacenter'da aynÄ± Ethernet fabric Ã¼zerinde GPU clusters, Oracle Database ve HPC workloads Ã§alÄ±ÅŸÄ±yor.
> **SÄ±nav Ä°pucu:** "RoCE", "converged ethernet", "strategic bet", "shared fabric"

### 4.3 OCI RDMA Supercluster
* **Basit TanÄ±m:** On binlerce GPU'nun tek bir network iÃ§inde konuÅŸabildiÄŸi dev cluster.
* **Teknik TanÄ±m:** Three-tier Clos network ile tens of thousands (100,000+) GPU'yu single RDMA network iÃ§inde destekleyen lossless networking infrastructure.

**Architecture:**
* Three-tier Clos network
* Block-based (her block = two-tier Clos)
* Non-blocking fabric (any-to-any communication)
* QoS-enabled, buffering optimized

**Bandwidth:**
* 200 Gbps per GPU
* 1.6 Tbps per 8-GPU node

**Ne Zaman Kullan:**
* Very large-scale AI training (10K+ GPUs)
* Distributed LLM training
* Massive parallel computing

**Ne Zaman Kullanma:**
* Small workloads (1-8 GPU)
* Ultra-low latency absolute priority, scale deÄŸil

**Ã–rnek:** 50,000 GPU ile GPT-6 benzeri model geliÅŸtiriliyor. TÃ¼m GPU'lar single network iÃ§inde iletiÅŸim kuruyor.
> **SÄ±nav Ä°pucu:** "Supercluster", "tens of thousands GPUs", "100K scale", "three-tier Clos", "lossless"

### 4.4 Latency DeÄŸerleri (Ã–NEMLI!)

| Scope | Latency (Round Trip) | Use Case |
| :--- | :--- | :--- |
| Intra-rack | < 6.5 Î¼s | Best performance |
| Intra-block | ~6.5 Î¼s | HPC, DB, small GPU |
| Inter-block | ~20 Î¼s | Large GPU workloads |
| Cloud (typical) | 200-400 Î¼s | 10-20x daha kÃ¶tÃ¼! |

**Not:** 20 Î¼s hala typical cloud'dan 10-20x daha iyi!

### 4.5 Block (Architecture)
* **Basit TanÄ±m:** Supercluster iÃ§indeki mahalleler - her block kendi iÃ§inde daha hÄ±zlÄ±.
* **Teknik TanÄ±m:** Organizational unit. Her block kendi two-tier Clos fabric'e sahip. Intra-block 6.5Î¼s, inter-block 20Î¼s.

**Ne Zaman Single Block:**
* Latency-sensitive workloads
* HPC clusters
* Database clusters
* Small to medium GPU workloads

**Ã–rnek:** Oracle Database cluster deploy ediliyor. Control plane single block'a yerleÅŸtiriyor, 6.5 Î¼s latency alÄ±yor.
> **SÄ±nav Ä°pucu:** "block", "intra-block 6.5Î¼s", "inter-block 20Î¼s", "single block placement"

### 4.6 Three-Tier Clos Network
* **Basit TanÄ±m:** ÃœÃ§ katlÄ± trafik sistemi - herkes herkesle konuÅŸabilir ama bazen daha fazla kavÅŸaktan geÃ§ersin.
* **Teknik TanÄ±m:** Non-blocking network design, 3 hierarchy. 100,000+ GPUs destekler. QoS-enabled, buffering optimized for lossless.

**Ne Zaman Kullan:**
* Massive scale (10K+ GPUs)
* Non-blocking fabric
* Scalability priority

> **SÄ±nav Ä°pucu:** "three-tier Clos", "non-blocking", "200 Gbps per GPU", "1.6 Tbps per node"

### 4.7 Lossless Networking
* **Basit TanÄ±m:** HiÃ§ paket kaybetmeyen network - switch'ler paketi dÃ¼ÅŸÃ¼rmez.
* **Teknik TanÄ±m:** Switches don't drop packets. Intelligent congestion notification. Higher buffers, QoS-enabled. RDMA requirement.

**Ne Zaman Kullan:**
* RDMA workloads (mandatory)
* GPU distributed training
* Packet loss tolere edilemez

**Ã–rnek:** Distributed training sÄ±rasÄ±nda gradient updates paylaÅŸÄ±lÄ±yor. Tek paket kaybÄ± iteration'Ä± bozar. Lossless networking ile hiÃ§bir paket kaybolmuyor.
> **SÄ±nav Ä°pucu:** "lossless", "no packet drop", "congestion notification", "RDMA requirement"

### 4.8 Network Locality Hints
* **Basit TanÄ±m:** "Bu GPU'lar yan yana, bunlar uzak" bilgisini veren harita - traffic'in Ã§oÄŸu yakÄ±nda kalÄ±r.
* **Teknik TanÄ±m:** Control plane'den gelen topology information. GPU topology optimize edilir. Intra-rack/intra-block traffic maximization.

**Benefit:**
* 85% traffic intra-block
* 50% traffic intra-rack
* Average latency dÃ¼ÅŸer
* Flow collision azalÄ±r
* Throughput artar

**Ne Zaman Kullan:**
* Multi-block workloads
* Latency optimization
* Throughput maximization

**Ã–rnek:** 64-GPU workload 2 block'a yayÄ±lmÄ±ÅŸ. Locality hints ile %85 traffic intra-block kalÄ±yor, average latency 7-8Î¼s (20Î¼s yerine).
> **SÄ±nav Ä°pucu:** "locality hints", "placement hints", "intra-block traffic", "flow collision reduction"

### 4.9 NVLink
* **Basit TanÄ±m:** NVIDIA GPU'larÄ±n kendi aralarÄ±nda konuÅŸtuÄŸu Ã¶zel kanal - 8 GPU tek node iÃ§inde NVLink ile baÄŸlÄ±.
* **Teknik TanÄ±m:** NVIDIA proprietary GPU-to-GPU interconnect within single node. 8x GPU per node.

**KullanÄ±m:**
* Intra-node GPU communication
* Single-node multi-GPU training

**Not:** Cross-node communication iÃ§in RDMA kullanÄ±lÄ±r.
> **SÄ±nav Ä°pucu:** "NVLink", "intra-node", "8 GPUs per node", "single node"

### 4.10 ÃœÃ§ Ana Optimizasyon
1.  **Buffer Tuning:**
    * QoS-enabled switches
    * Worst-case latency iÃ§in buffers
    * Lossless operation garanti

2.  **Placement Control:**
    * HPC/DB â†’ single block (6.5Î¼s)
    * Small GPU â†’ single block
    * Large GPU â†’ multi-block optimized

3.  **Locality Hints:**
    * Network topology transparency
    * 85% intra-block, 50% intra-rack
    * Flow collision azaltma
    * Higher throughput

#### ğŸ¯ RDMA HÄ±zlÄ± Karar Tablosu

| Soruda Bu Var | Bu KavramÄ± SeÃ§ |
| :--- | :--- |
| Bypass CPU, low latency | **RDMA** |
| Ethernet, converged | **RoCE** |
| Tens of thousands GPUs | **Supercluster** |
| 6.5 microseconds | **Intra-block** |
| 20 microseconds | **Inter-block** |
| No packet drop | **Lossless** |
| Topology optimization | **Locality hints** |
| 8 GPUs single node | **NVLink** |

---

## 5. RESPONSIBLE AI

### 5.1 Trustworthy AI - ÃœÃ§ Temel Ä°lke
1.  **LAWFUL (Yasal)**
    * TÃ¼m yasa ve dÃ¼zenlemelere uyumlu
    * Domain-specific rules (tÄ±bbi cihaz dÃ¼zenlemeleri)
    * HaklarÄ± korur (azÄ±nlÄ±klar, Ã§evre)

2.  **ETHICAL (Etik)**
    * Human dignity (insan onuru)
    * Freedom & privacy (Ã¶zgÃ¼rlÃ¼k & gizlilik)
    * Democracy & equality (demokrasi & eÅŸitlik)
    * No unfair bias (ayrÄ±mcÄ±lÄ±k yok)

3.  **ROBUST (SaÄŸlam)**
    * Teknik aÃ§Ä±dan saÄŸlam
    * Sosyal aÃ§Ä±dan saÄŸlam
    * Unintentional harm Ã¶nleme

### 5.2 AI Ethics - ÃœÃ§ Ana Ä°lke
1.  **Help Humans & Allow Oversight**
    * Human-in-the-loop
    * Meaningful choice
    * Human oversight
    * Augment not replace

2.  **Never Cause Harm**
    * Physical harm Ã¶nleme
    * Social harm Ã¶nleme
    * Safety & security
    * Technical robustness

3.  **Transparent & Fair**
    * Explainable decisions
    * Fair (no bias)
    * Transparent reasoning

### 5.3 Human-Centric Design
* **Basit TanÄ±m:** AI insanÄ±n hizmetkarÄ± olmalÄ±, patronu deÄŸil - insan her zaman kontrolde.
* **Teknik TanÄ±m:** AI follows principles leaving meaningful opportunity for human choice. Human oversight guaranteed.

**Ne Zaman Kullan:**
* Critical decision systems (medical, legal)
* High-impact automation
* Safety-critical applications

**Ã–rnek:** Doktor AI'dan rÃ¶ntgen analizi istiyor. AI Ã¶neri sunuyor ama final teÅŸhisi doktor koyuyor.
> **SÄ±nav Ä°pucu:** "human-centric", "human oversight", "meaningful choice", "human-in-the-loop"

### 5.4 AI Fairness & Bias Prevention
* **Basit TanÄ±m:** AI herkese adil davanmalÄ± - bir Ä±rka, cinsiyete, gruba ayrÄ±mcÄ±lÄ±k yapmamalÄ±.
* **Teknik TanÄ±m:** Equal and just distribution of benefits/costs. Free from unfair bias and discrimination. Consistent performance across demographics.

**Ne Zaman Kullan:**
* Healthcare AI
* Hiring/recruitment systems
* Loan approval systems
* Any decision affecting people

**Ã–rnek:** AI iÅŸe alÄ±m sistemi Ã§oÄŸunlukla erkek data ile train edilmiÅŸ. KadÄ±n adaylarÄ± unfairly skorluyor. Bias detect edilip data balanced ediliyor.
> **SÄ±nav Ä°pucu:** "fairness", "bias", "discrimination", "equal distribution", "demographic parity"

### 5.5 AI Explainability
* **Basit TanÄ±m:** AI'Ä±n kararÄ±nÄ± aÃ§Ä±klayabilmesi - "neden bu sonuca vardÄ±n?" sorusuna cevap vermeli.
* **Teknik TanÄ±m:** Decisions should be explainable to affected parties. Humans must understand reasoning. Transparency in decision-making.

**Ne Zaman Kullan:**
* Healthcare decisions
* Credit/loan rejections
* Legal decisions
* Regulatory compliance (GDPR)

**Ã–rnek:** Kredi reddediliyor. AI: "Debt-to-income %60 (limit %40), 3 Ã¶deme gecikmesi, kredi skoru 580 (minimum 620)".
> **SÄ±nav Ä°pucu:** "explainability", "transparency", "interpretability", "reasoning", "trust"

### 5.6 AI Safety & Security
* **Basit TanÄ±m:** AI gÃ¼venli ve saÄŸlam olmalÄ± - hack'lenemez, kÃ¶tÃ¼ye kullanÄ±lamaz.
* **Teknik TanÄ±m:** Systems must be safe and secure. Technically robust, not open to malicious use. Adversarial attack resistant.

**Ne Zaman Kullan:**
* Critical infrastructure AI
* Healthcare systems
* Financial systems
* Autonomous vehicles

**Ã–rnek:** Otonom araÃ§ vision sistemi adversarial attack'e karÅŸÄ± test ediliyor, robust hale getiriliyor.
> **SÄ±nav Ä°pucu:** "safety", "security", "robust", "malicious use prevention", "adversarial resistance"

### 5.7 Responsible AI Implementation
**ÃœÃ§ AdÄ±m:**
1.  **GOVERNANCE**
    * YÃ¶netim yapÄ±sÄ± kurulumu
    * â†“
2.  **POLICIES & PROCEDURES**
    * Kurallar ve prosedÃ¼rler
    * â†“
3.  **MONITORING & EVALUATION**
    * DÃ¼zenli izleme ve deÄŸerlendirme

**Roller:**
* **Developers:** AI system geliÅŸtirme
* **Deployers:** Deploy ve operasyon
* **End Users:** Sistemi kullanma

**Ã–rnek:** Åirket AI governance board kuruyor, AI usage policies yazÄ±yor, her quarter audit yapÄ±yor.
> **SÄ±nav Ä°pucu:** "governance", "policies", "procedures", "monitoring", "compliance"

### 5.8 Healthcare AI Challenges
**Challenge 1: Fairness & Bias**
* **Problem:** Biased training data (single demographic)
* **Etki:** Poor performance on underrepresented groups
* **Ã‡Ã¶zÃ¼m:** Diverse, representative datasets

**Challenge 2: Transparency & Trust**
* **Problem:** Complex algorithms, black box
* **Etki:** Difficulty trusting AI
* **Ã‡Ã¶zÃ¼m:** Explainability, regular evaluation

**Ã–rnek:** Deri kanseri AI'Ä± aÃ§Ä±k tenli hastalarda eÄŸitilmiÅŸ, koyu tenli hastalarda %40 accuracy dÃ¼ÅŸÃ¼yor. Data augment ediliyor, model retrain ediliyor.
> **SÄ±nav Ä°pucu:** "healthcare AI", "fairness challenge", "bias in medical data", "diverse datasets"

#### ğŸ¯ Responsible AI HÄ±zlÄ± Karar Tablosu

| Soruda Bu Var | Bu KavramÄ± SeÃ§ |
| :--- | :--- |
| Lawful, ethical, robust | **Trustworthy AI (3 pillars)** |
| Help humans, no harm, transparent | **AI Ethics (3 principles)** |
| Human oversight, meaningful choice | **Human-centric design** |
| Equal treatment, no discrimination | **Fairness & Bias** |
| Why this decision?, reasoning | **Explainability** |
| Adversarial attack, security | **Safety & Security** |
| Governance, policies, monitoring | **Implementation process** |
| Healthcare, one demographic | **Fairness challenge** |

---

## 6. SINAV STRATEJÄ°SÄ°

### 6.1 Genel YaklaÅŸÄ±m
1.  **Anahtar Kelimeleri TanÄ±**
    * Soruda geÃ§en critical keywords'leri iÅŸaretle
    * Hangi service/component'i iÅŸaret ediyor?
2.  **Use-Case'e Bak**
    * "Ne zaman kullan" senaryolarÄ±nÄ± hatÄ±rla
    * Anti-pattern'leri elemele
3.  **Kritik AyrÄ±mlarÄ± Bil**
    * Benzer kavramlarÄ± karÄ±ÅŸtÄ±rma
    * Her birinin unique Ã¶zelliÄŸini bil

### 6.2 Kritik AyrÄ±mlar
* **AI Services vs Data Science:**
    * AI Services = Prebuilt, no data science expertise
    * Data Science = Custom models, Python coding required
* **Vision OCR vs Document Understanding:**
    * Vision = Resimlerdeki metin (foto, billboard)
    * Document Understanding = Strukturlu belgeler (fatura, form)
* **Notebook vs Jobs:**
    * Notebook = Interactive, development
    * Jobs = Automated, scheduled, production
* **Model Catalog vs Model Deployment:**
    * Catalog = Storage, versioning, sharing
    * Deployment = Serving, HTTP endpoint, production
* **RDMA vs RoCE:**
    * RDMA = Technology (CPU bypass)
    * RoCE = Protocol (RDMA over Ethernet)
* **Intra-block vs Inter-block:**
    * Intra-block = 6.5 Î¼s (same block)
    * Inter-block = 20 Î¼s (different blocks)
* **H100 vs H200:**
    * AynÄ± architecture (Hopper)
    * H200 = H100 + more memory
* **Fairness vs Explainability:**
    * Fairness = Equal outcomes across groups
    * Explainability = Understanding why decision made

### 6.3 HÄ±zlÄ± Referans Tablosu

| Kategori | Anahtar Kelime / Use Case | Servis / Kavram |
| :--- | :--- | :--- |
| **AI Services** | Text analysis, sentiment, PII | Language |
| | Image, object detection, OCR | Vision |
| | Audio, speech-to-text | Speech |
| | Invoice, table extraction | Document Understanding |
| | Chatbot, conversation | Digital Assistant |
| **Data Science** | JupyterLab, interactive | Notebook Sessions |
| | Organize, workspace | Projects |
| | Model storage, versioning | Model Catalog |
| | HTTP endpoint, real-time | Model Deployments |
| | Scheduled, repeatable | Jobs |
| | Package management | Conda |
| | AutoML, simplify | ADS SDK |
| **GPU** | Transformer, LLM, 2022 | H100 |
| | More memory, 2024 | H200 |
| | Latest, Blackwell, 2025 | B200 |
| | Superchip, CPU+GPU | GB200 |
| | Cost-effective, small | L40/L4 |
| **RDMA** | Bypass CPU, low latency | RDMA |
| | Converged ethernet | RoCE |
| | Tens of thousands GPUs | Supercluster |
| | 6.5 microseconds | Intra-block |
| | 20 microseconds | Inter-block |
| | No packet drop | Lossless |
| | Topology optimization | Locality hints |
| **Responsible AI** | Lawful, ethical, robust | Trustworthy AI |
| | Help humans, no harm, transparent | AI Ethics |
| | Human oversight | Human-centric |
| | No discrimination | Fairness |
| | Why this decision | Explainability |
| | Security, adversarial | Safety & Security |

### 6.4 SÄ±nav Ä°puÃ§larÄ±
âœ… **Dikkat Et:**
* Anahtar kelimeleri vurgula
* "Ne zaman kullan" senaryolarÄ±nÄ± hatÄ±rla
* SayÄ±larÄ± bil (6.5Î¼s, 20Î¼s, 200 Gbps, etc.)
* Timeline'Ä± bil (2020â†’A100, 2022â†’H100, 2024â†’H200, 2025â†’B200)

âŒ **Tuzaklara DÃ¼ÅŸme:**
* Benzer isimleri karÄ±ÅŸtÄ±rma (H100 vs H200)
* Use-case'i yanlÄ±ÅŸ eÅŸleÅŸtirme
* Anti-pattern'leri seÃ§me

ğŸ¯ **Strateji:**
1.  Soruyu iki kez oku
2.  Anahtar kelimeleri iÅŸaretle
3.  Hangi kategori (AI Service, Data Science, GPU, RDMA, Responsible)?
4.  Ä°lgili hÄ±zlÄ± referans tablosuna bak
5.  CevabÄ± iÅŸaretle

### 6.5 Ã–rnek Sorular ve Ã‡Ã¶zÃ¼m YaklaÅŸÄ±mÄ±

**Soru Tipi 1: "Which service for..."**
* *"Which OCI AI service for sentiment analysis?"*
* Anahtar: "sentiment analysis"
* Tablo: AI Services â†’ sentiment â†’ **Language** âœ…

**Soru Tipi 2: "What is the advantage..."**
* *"What is advantage of Supercluster?"*
* Anahtar: "Supercluster", "advantage"
* HatÄ±rla: Tens of thousands GPUs, massive scale
* Cevap: **Exceptional performance & scalability** âœ…

**Soru Tipi 3: "Which feature allows..."**
* *"Which feature allows catalogued models as HTTP endpoints?"*
* Anahtar: "catalogued models", "HTTP endpoints"
* Tablo: Data Science â†’ HTTP endpoint â†’ **Model Deployments** âœ…

**Soru Tipi 4: "What latency..."**
* *"What is intra-block latency?"*
* Ezber: Intra-block = **6.5 Î¼s** âœ…

---

## ğŸ¯ SON KONTROL LÄ°STESÄ°

**SÄ±nava girmeden Ã¶nce:**

* **AI Services:**
    * [ ] Her servisin ne yaptÄ±ÄŸÄ±nÄ± biliyorum
    * [ ] Vision OCR vs Document Understanding ayrÄ±mÄ±nÄ± biliyorum
    * [ ] Use-case'leri biliyorum
* **Data Science:**
    * [ ] ADS SDK workflow'unu biliyorum (6 adÄ±m)
    * [ ] Notebook vs Jobs ayrÄ±mÄ±nÄ± biliyorum
    * [ ] Model Catalog vs Deployment ayrÄ±mÄ±nÄ± biliyorum
* **GPU:**
    * [ ] GPU timeline'Ä± biliyorum (2020â†’2025)
    * [ ] Her GPU'nun key feature'Ä±nÄ± biliyorum
    * [ ] Performance karÅŸÄ±laÅŸtÄ±rmalarÄ±nÄ± biliyorum
* **RDMA:**
    * [ ] Latency deÄŸerlerini biliyorum (6.5Î¼s, 20Î¼s)
    * [ ] Three-tier Clos architecture'Ä± biliyorum
    * [ ] Locality hints'i biliyorum
* **Responsible AI:**
    * [ ] 3 pillars biliyorum (Lawful, Ethical, Robust)
    * [ ] 3 principles biliyorum (Help, No harm, Transparent)
    * [ ] Implementation process biliyorum (3 steps)

---

## ğŸ“š Kaynaklar
Bu Ã¶zet, Oracle Cloud Infrastructure AI Foundations eÄŸitim transkriptlerinden hazÄ±rlanmÄ±ÅŸtÄ±r:
* OCI AI Services Overview
* OCI ML Services Overview
* GPU & AI Infrastructure
* RDMA & Supercluster
* Responsible AI
* OCI Data Science Demo