# ğŸ“š GÃœN 3: CNN & SEQUENCE MODELS - Ã–ZET NOTLAR

## ğŸ¯ CNN (CONVOLUTIONAL NEURAL NETWORK)

### 7 DL Model Mimarisi (EZBER!)
1. **FNN** (Feedforward/MLP) - En basit
2. **CNN** - Images/videos iÃ§in
3. **RNN** - Sequential data iÃ§in
4. **Autoencoders** - Unsupervised, dimensionality reduction
5. **LSTM** - Long-term dependencies
6. **GAN** - Generative (image, audio, text Ã¼retimi)
7. **Transformers** - NLP iÃ§in state-of-the-art

---

### CNN Nedir?
**TanÄ±m:** Grid-like data (images, videos) iÃ§in Ã¶zel DL modeli

**Neden CNN?**
- **2D data** ile iyi Ã§alÄ±ÅŸÄ±r (image inherently 2D)
- ANN â†’ 1D array (iyi deÄŸil)
- CNN â†’ 2D (mÃ¼kemmel!)

**AmaÃ§:** Image'i iÅŸlenebilir form'a indirgemek, kritik features'Ä± kaybetmeden

---

### CNN Mimarisi (Katmanlar)

```
Input Layer
    â†“
Feature Extraction Layers (tekrarlanabilir)
    â”œâ”€ Convolutional Layer + ReLU
    â””â”€ Pooling Layer
    â†“
Classification Layer
    â””â”€ Fully Connected + Softmax
```

---

### Feature Extraction Layers (Robot Analojisi)

| Robot Tool | CNN Layer | GÃ¶rev |
|------------|-----------|-------|
| Blueprint Detector | **Convolutional Layer** | Pattern tespit (edges, corners) |
| Pattern Highlighter | **Activation (ReLU)** | Non-linear iliÅŸkiler |
| Room Summarizer | **Pooling Layer** | Spatial dimension azalt |
| House Expert | **Fully Connected** | Final prediction |
| Guess Maker | **Softmax** | Probability scores |
| Quality Checker | **Dropout** | Overfitting Ã¶nleme |

---

### Convolutional Layer
**GÃ¶rev:** Convolutional operations uygular
**AraÃ§:** Filters/Kernels (kÃ¼Ã§Ã¼k filtreler)
**Tespit:** Edges, corners, textures
**NasÄ±l:** Filter slides across image

### Activation Function (ReLU)
**GÃ¶rev:** Non-linear relationships Ã¶ÄŸrenir
**Ne zaman:** Her convolution sonrasÄ±

### Pooling Layer
**GÃ¶rev:** Spatial dimensions azaltÄ±r
**SonuÃ§:** âœ… Computational complexity â†“, âœ… Ã–nemli features korunur

### Fully Connected Layer
**GÃ¶rev:** Final prediction/classification
**Girdi:** Extracted features

### Softmax Layer
**GÃ¶rev:** Output â†’ Probability scores
**SeÃ§im:** En yÃ¼ksek probability = Predicted class

### Dropout Layer
**GÃ¶rev:** Overfitting Ã¶nleme
**NasÄ±l:** Randomly bazÄ± neurons devre dÄ±ÅŸÄ±

---

### CNN Limitasyonlar
âŒ Computationally expensive (bÃ¼yÃ¼k data)
âŒ Overfitting (limited/imbalanced data)
âŒ Black box (yorumlanamaz)
âŒ Input deÄŸiÅŸikliklerine hassas

### CNN Uygulamalar
âœ… Image classification (cat/dog)
âœ… Object detection (bounding boxes)
âœ… Pixel-level segmentation
âœ… Face recognition
âœ… Medical image analysis (tumor detection)
âœ… Self-driving cars (traffic signs, pedestrians)
âœ… Satellite image analysis

---

## ğŸ”„ SEQUENCE MODELS (RNN & LSTM)

### Sequence Models Nedir?
**TanÄ±m:** Sequential data (ordered lists) iÅŸleyen modeller
**AmaÃ§:** Pattern, dependencies bulma â†’ Prediction/classification/generation

### Sequential Data Ã–rnekleri
- Text paragraphs
- Time series (finans, hava)
- Speech/audio
- Hand gestures
- Music

---

### RNN (Recurrent Neural Network)

**Ã–zellik:** Sequential data iÃ§in Ã¶zel tasarÄ±m
**Fark:** Feedforward'dan farklÄ± â†’ **Feedback loop** var
**Anahtar:** **Hidden state/memory** tutar

**Hidden State:**
- Internal state
- Her time step'te gÃ¼ncellenir
- Next time step iÃ§in input olur
- Temporal dependencies yakalar

---

### RNN Mimarileri (4 TÃ¼r)

| Mimari | Input | Output | Uygulama |
|--------|-------|--------|----------|
| **One-to-One** | 1 | 1 | Feedforward (sequential deÄŸil) |
| **One-to-Many** | 1 | Ã‡ok | Music generation |
| **Many-to-One** | Ã‡ok | 1 | Sentiment analysis |
| **Many-to-Many** | Ã‡ok | Ã‡ok | Machine translation |

---

### RNN Sorunu: Vanishing Gradient
**Problem:** Long-term dependencies yakalanamÄ±yor
**Ã‡Ã¶zÃ¼m:** **LSTM**

---

### LSTM (Long Short-Term Memory)

**TanÄ±m:** RNN variant, long-term dependencies iÃ§in
**AmaÃ§:** Vanishing gradient problemini Ã§Ã¶zer

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- **Memory cell** kullanÄ±r
- **Gating mechanisms** (kapÄ± mekanizmalarÄ±)
- Bilgiyi **selectively** hatÄ±rlar/unutur

---

### LSTM BileÅŸenleri

**Her Time Step'te:**
1. **Input vector:** Mevcut data point
2. **Previous hidden state:** Ã–nceki durum
3. **Previous cell state:** Ã–nceki hafÄ±za

**3 Gate (KapÄ±):**

**1. Input Gate:**
- Ne kadar yeni bilgi eklenecek?
- Memory cell'e ekleme kontrolÃ¼

**2. Forget Gate:**
- Ne kadar eski bilgi unutulacak?
- Memory cell'den Ã§Ä±karma kontrolÃ¼

**3. Output Gate:**
- Ne kadar bilgi output olacak?
- Current time step Ã§Ä±ktÄ±sÄ±

---

### LSTM Ã‡alÄ±ÅŸma SÃ¼reci

```
1. Input + Previous states al
    â†“
2. Input Gate: Yeni bilgi filtrele
    â†“
3. Forget Gate: Eski bilgi filtrele
    â†“
4. Cell State gÃ¼ncelle
    â†“
5. Output Gate: Output Ã¼ret
    â†“
6. Hidden state â†’ Next time step
```

**SonuÃ§:** Long sequences Ã¼zerinde relevant bilgiyi tutar

---

## ğŸ¯ SINAV Ä°Ã‡Ä°N KRÄ°TÄ°K KAVRAMLAR

### CNN
- âœ… 7 DL mimari: FNN, CNN, RNN, Autoencoders, LSTM, GAN, Transformers
- âœ… CNN = 2D data (images/videos)
- âœ… Convolutional layer = Pattern detection
- âœ… Pooling = Spatial dimension azaltma
- âœ… Softmax = Probability
- âœ… Dropout = Overfitting Ã¶nleme

### RNN/LSTM
- âœ… RNN = Sequential data, feedback loop, hidden state
- âœ… 4 mimari: One-to-one, One-to-many, Many-to-one, Many-to-many
- âœ… LSTM = Long-term dependencies
- âœ… 3 Gates: Input, Forget, Output
- âœ… Vanishing gradient â†’ LSTM Ã§Ã¶zer

### Uygulamalar
- **CNN:** Image classification, object detection, face recognition, medical imaging
- **RNN:** NLP, sentiment, translation
- **LSTM:** Long sequences, speech, time series

### KarÅŸÄ±laÅŸtÄ±rma
- **ANN â†’ 1D:** Ä°yi deÄŸil images iÃ§in
- **CNN â†’ 2D:** MÃ¼kemmel images iÃ§in
- **RNN â†’ Sequential:** Feedback loop
- **LSTM â†’ Long-term:** Gates ile

---

## ğŸ“ SON KONTROL

- [ ] 7 DL mimarisi sayabilir misin?
- [ ] CNN neden 2D data iÃ§in?
- [ ] Convolutional layer ne yapar?
- [ ] Pooling layer gÃ¶revi?
- [ ] RNN vs Feedforward fark?
- [ ] 4 RNN mimarisi?
- [ ] LSTM 3 gate?
- [ ] Vanishing gradient nedir?

**EVET demeliyiz!**