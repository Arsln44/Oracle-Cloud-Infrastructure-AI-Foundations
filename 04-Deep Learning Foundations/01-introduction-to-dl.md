# ğŸ“š GÃœN 3: DEEP LEARNING - INTRODUCTION - DetaylÄ± Ã‡alÄ±ÅŸma Notu

## ğŸ¯ ModÃ¼l Ã–zeti
Bu modÃ¼l Deep Learning'in tanÄ±mÄ±nÄ±, ANN (Artificial Neural Network) yapÄ±sÄ±nÄ±, tarihÃ§esini ve temel kavramlarÄ± aÃ§Ä±klÄ±yor.

---

## ğŸ§  DEEP LEARNING NEDÄ°R?

### TanÄ±m
**Deep Learning (DL):** Machine learning'in bir alt kÃ¼mesi. **Artificial Neural Networks (ANN)** eÄŸiterek gÃ¶revleri Ã§Ã¶zer.

**HiyerarÅŸi:**
```
AI âŠƒ ML âŠƒ DL
```

### Ã–rnek GÃ¶rev
**Image Classification** (GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma)

---

## ğŸ”‘ ANN'NÄ°N Ã–NEMLÄ° Ã–ZELLÄ°ÄÄ°

**Raw Data Ä°ÅŸleyebilme:**
- **Pixels** (pikseller) gibi ham veriyi iÅŸler
- Bu veriden **patterns (desenler)** Ã§Ä±karÄ±r
- Pattern'ler **features (Ã¶zellikler)** olarak kullanÄ±lÄ±r
- Bu Ã¶zelliklerle **outcome (sonuÃ§)** tahmin eder

**ğŸ’¡ En Ã–nemli Fark: Otomatik feature extraction!**

---

## âœï¸ HANDWRITTEN DIGIT RECOGNITION Ã–RNEÄÄ°

### Problem
**GÃ¶rev:** 0-9 arasÄ± el yazÄ±sÄ± rakamlarÄ± tanÄ±ma

**Zorluk:** Herkes rakamlarÄ± farklÄ± yazar

### ANN Ã‡Ã¶zÃ¼mÃ¼

**1. Input:** Image pixels (28Ã—28 = 784 piksel)

**2. Pattern Extraction:**
- Edges (kenarlar)
- Curves (eÄŸriler)
- DiÄŸer desenler

**3. Correlation:** Pattern'leri iliÅŸkilendirir

**4. Prediction:** Hangi rakam? (0-9)

**Ã–zet:** Bir sÃ¼rÃ¼ pikselden â†’ ANN â†’ Internal representation â†’ Prediction

---

## ğŸ†š ML vs DEEP LEARNING FARKI

### Machine Learning
**Feature Engineering:**
- Features **manuel** belirtilir
- Ä°nsan Ã¶zellikleri tanÄ±mlar
- Zaman alÄ±cÄ±

### Deep Learning
**Automatic Feature Extraction:**
- Features **otomatik** Ã§Ä±karÄ±lÄ±r
- Veriden Ã¶ÄŸrenir
- Internal representation oluÅŸturur
- Manuel olarak mÃ¼mkÃ¼n olmayan kombinasyonlar

**ğŸ’¡ DL'nin GÃ¼cÃ¼: Otomatik feature learning!**

---

## âš¡ DEEP LEARNING AVANTAJLARI

### 1. Parallel Computation (Paralel Hesaplama)
**NasÄ±l:**
- Data kÃ¼Ã§Ã¼k **batches** (gruplara) bÃ¶lÃ¼nÃ¼r
- Paralel iÅŸlenir

**SonuÃ§:**
- âœ… BÃ¼yÃ¼k veri kÄ±sa sÃ¼rede iÅŸlenir
- âœ… **Scalability** (Ã¶lÃ§eklenebilirlik)
- âœ… **Performance** (performans)

### 2. Kompleks Veri Ä°ÅŸleme
**Ne Zaman DL Kullan:**
- KarmaÅŸÄ±k veri
- Features kolayca tanÄ±mlanamÄ±yor
- ML algoritmalarÄ± yetersiz

**ğŸ’¡ DL complements (tamamlar) ML'yi karmaÅŸÄ±k veri iÃ§in**

---

## ğŸ“œ DEEP LEARNING TARÄ°HÃ‡ESÄ°

### 1950s - Ä°lk Kavramlar
- Artificial Neuron
- Perceptron
- Multi-layer Perceptron

### 1980s - Backpropagation
**En Ã¶nemli konsept:** Backpropagation algoritmasÄ± training iÃ§in

### 1990s - CNN
**Convolutional Neural Networks** image analysis iÃ§in tanÄ±tÄ±ldÄ±

### 2000 - GPU'lar
**GPU (Graphics Processing Unit)** tanÄ±tÄ±ldÄ±

### 2010+ - GPU YaygÄ±nlaÅŸmasÄ±
- GPU ucuzladÄ±, yaygÄ±nlaÅŸtÄ±
- **DL patlamasÄ± baÅŸladÄ±!**

**KullanÄ±m AlanlarÄ±:**
- Computer Vision
- Natural Language Processing (NLP)
- Speech Recognition
- Text Translation

### 2012 - BÃ¼yÃ¼k AÄŸlar
- **AlexNet**
- **Deep Q-Network**

### 2016+ - Generative Use Cases
Generative AI kullanÄ±m alanlarÄ± baÅŸladÄ±

### BugÃ¼n
- **Large Language Models (LLM)**
- Ã‡eÅŸitli generative modeller
- GeniÅŸ kullanÄ±m alanlarÄ±

**ğŸ’¡ GPU = DL'nin yÃ¼kseliÅŸindeki anahtar faktÃ¶r**

---

## ğŸ¯ DL UYGULAMALARI (VERÄ° TÄ°PLERÄ°NE GÃ–RE)

### 1. Images (GÃ¶rÃ¼ntÃ¼ler)

| Uygulama | AÃ§Ä±klama |
|----------|----------|
| **Image Classification** | GÃ¶rÃ¼ntÃ¼yÃ¼ sÄ±nÄ±flandÄ±rma |
| **Object Detection** | Nesneleri tespit etme |
| **Image Segmentation** | Piksel seviyesinde ayÄ±rma |
| **Facial Recognition** | YÃ¼z tanÄ±ma |

**Ã–nerilen Mimari: CNN**

---

### 2. Videos (Videolar)

| Uygulama | AÃ§Ä±klama |
|----------|----------|
| **Action Recognition** | Hareket tanÄ±ma |
| **Video Classification** | Video sÄ±nÄ±flandÄ±rma |

**Ã–nerilen Mimari: CNN + RNN**

---

### 3. Text (Metin)

| Uygulama | AÃ§Ä±klama |
|----------|----------|
| **Text Translation** | Metin Ã§evirisi |
| **Sentiment Detection** | Duygu analizi |
| **Text Summarization** | Metin Ã¶zetleme |
| **Question Answering** | Soru cevaplama |

**Ã–nerilen Mimari:**
- **Transformers** (en yeni, en iyi)
- LSTM
- RNN

---

### 4. Audio (Ses)

| Uygulama | AÃ§Ä±klama |
|----------|----------|
| **Music Generation** | MÃ¼zik Ã¼retimi |
| **Speech-to-Text** | KonuÅŸmadan metine |
| **Text-to-Speech** | Metinden konuÅŸmaya |

**Ã–nerilen Mimari: RNN, LSTM, Transformers**

---

### 5. Generative Tasks (Ãœretken GÃ¶revler)

| Uygulama | AÃ§Ä±klama | Mimari |
|----------|----------|--------|
| **Text-to-Image** | Metinden gÃ¶rÃ¼ntÃ¼ | Transformers, GANs, Diffusion |
| **Image Generation** | GÃ¶rÃ¼ntÃ¼ Ã¼retimi | GANs, Diffusion |

---

## ğŸ§  ARTIFICIAL NEURAL NETWORK (ANN)

### Ä°lham KaynaÄŸÄ±
**Human Brain (Ä°nsan Beyni)**

### YapÄ±
**Interconnected Nodes:** Birbirine baÄŸlÄ± dÃ¼ÄŸÃ¼mler

**Node = Neuron**

---

## ğŸ”§ ANN NASIL Ã‡ALIÅIR?

### Basit AÃ§Ä±klama

**1. Weights (AÄŸÄ±rlÄ±klar):**
- Neuronlar arasÄ± baÄŸlantÄ±lara atanÄ±r
- Connection strength (baÄŸlantÄ± gÃ¼cÃ¼)

**2. Weighted Sum:**
- Weighted inputs toplanÄ±r

**3. Threshold:**
- Toplam belirli bir eÅŸiÄŸi geÃ§erse â†’ Neuron fires (ateÅŸlenir)

**4. Layer to Layer:**
- Bir katmanÄ±n outputu â†’ DiÄŸer katmanÄ±n inputu

---

## ğŸ—ï¸ ANN BUILDING BLOCKS (5 BileÅŸen)

### 1. LAYERS (Katmanlar)

**a) Input Layer (GiriÅŸ KatmanÄ±):**
- **Mandatory (Zorunlu)**
- Ham veriyi alÄ±r
- Ã–rnek: 28Ã—28 = 784 piksel

**b) Hidden Layers (Gizli Katmanlar):**
- **Optional (Ä°steÄŸe baÄŸlÄ±)**
- Birden fazla olabilir
- Internal representation Ã¶ÄŸrenir
- Ne kadar Ã§ok â†’ "Deep" learning

**c) Output Layer (Ã‡Ä±kÄ±ÅŸ KatmanÄ±):**
- **Mandatory (Zorunlu)**
- Final prediction
- Ã–rnek: 10 neuron (0-9 rakamlar iÃ§in)

---

### 2. NEURONS (NÃ¶ronlar)

**TanÄ±m:** Computational units (Hesaplama birimleri)

**GÃ¶rev:**
- Input kabul eder
- Output Ã¼retir

---

### 3. WEIGHTS (AÄŸÄ±rlÄ±klar)

**TanÄ±m:** Connection strength (BaÄŸlantÄ± gÃ¼cÃ¼)

**Nerede:**
- Input â†’ Neuron arasÄ±
- Neuron â†’ Neuron arasÄ±

**DeÄŸiÅŸir:** Training sÄ±rasÄ±nda ayarlanÄ±r

---

### 4. ACTIVATION FUNCTIONS (Aktivasyon FonksiyonlarÄ±)

**GÃ¶rev:**
- Weighted sum Ã¼zerinde Ã§alÄ±ÅŸÄ±r
- Output Ã¼retir
- Non-linearity ekler

**Ã–rnekler:**
- ReLU
- Sigmoid
- Tanh

---

### 5. BIAS

**TanÄ±m:** Neuron'a ek input

**AmaÃ§:** Flexibility (Esneklik) saÄŸlar

---

## âœï¸ HANDWRITTEN DIGIT RECOGNITION - DETAYLI Ã–RNEK

### Veri Toplama
**Large number of digit images** topla

### ANN YapÄ±sÄ±

**Input Layer:**
- 28Ã—28 piksel = **784 input neurons**

**Hidden Layers:**
- 2 hidden layer (Ã¶rnek)
- Her biri **16 neurons**

**Output Layer:**
- **10 neurons** (0-9 rakamlar iÃ§in)

### GÃ¶revler

**Hidden Layers:**
- **Internal representation** Ã¶ÄŸrenir
- Raw image data'dan pattern Ã§Ä±karÄ±r

**Output Layer:**
- **Desired outcome** Ã¼retir
- Hangi rakam? (0-9)

---

## ğŸ”„ TRAINING SÃœRECÄ°: BACKPROPAGATION

### Ã–rnek Senaryo

**1. Image GÃ¶ster:**
- Digit "2" gÃ¶rÃ¼ntÃ¼sÃ¼

**2. Beklenen:**
- Output neuron for digit 2 fires

**3. GerÃ§ekleÅŸen:**
- Output neuron for digit 6 fires

**4. Hata (Error):**
- YanlÄ±ÅŸ tahmin!

---

### Backpropagation Algorithm

**AmaÃ§:** Error'Ä± dÃ¼zeltmek

**NasÄ±l:**
1. **Error hesapla**
2. **Weights'i ayarla** (calculation ile)
3. **Backward (geriye)** doÄŸru gÃ¼ncelle

**Ä°terasyon:**
- Binlerce image gÃ¶ster
- Her defasÄ±nda weights ayarla
- **Iteratively (yinelemeli)**

**SonuÃ§:**
- ANN Ã§oÄŸu input image iÃ§in doÄŸru tahmin yapar

**ğŸ’¡ Bu sÃ¼rece "Model Training" denir**

---

## ğŸ”‘ ANAHTAR KELÄ°MELER

### Temel Terimler
- âœ… **Deep Learning:** ML'nin alt kÃ¼mesi, ANN kullanÄ±r
- âœ… **ANN:** Artificial Neural Network
- âœ… **Neuron:** Hesaplama birimi
- âœ… **Layer:** Katman (Input, Hidden, Output)
- âœ… **Weights:** BaÄŸlantÄ± gÃ¼cÃ¼
- âœ… **Bias:** Esneklik iÃ§in ek input
- âœ… **Activation Function:** Non-linearity ekler

### Ã–zellikler
- âœ… **Raw Data Processing:** Ham veri iÅŸleme
- âœ… **Pattern Extraction:** Desen Ã§Ä±karma
- âœ… **Automatic Feature Extraction:** Otomatik Ã¶zellik Ã§Ä±karma
- âœ… **Internal Representation:** Ä°Ã§ temsil
- âœ… **Parallel Computation:** Paralel hesaplama
- âœ… **Batches:** KÃ¼Ã§Ã¼k gruplar

### Training
- âœ… **Backpropagation:** Geriye yayÄ±lÄ±m algoritmasÄ±
- âœ… **Model Training:** Model eÄŸitimi
- âœ… **Iteratively:** Yinelemeli
- âœ… **Adjust Weights:** AÄŸÄ±rlÄ±klarÄ± ayarlama

### Mimariler
- âœ… **CNN:** Convolutional Neural Network
- âœ… **RNN:** Recurrent Neural Network
- âœ… **LSTM:** Long Short-Term Memory
- âœ… **Transformers:** En yeni mimari
- âœ… **GANs:** Generative Adversarial Networks

### TarihÃ§e
- âœ… **GPU:** Graphics Processing Unit
- âœ… **AlexNet:** 2012'de Ã¶nemli aÄŸ
- âœ… **LLM:** Large Language Models

---

## ğŸ¯ SINAV Ä°Ã‡Ä°N KRÄ°TÄ°K

### Mutlaka Bilin:
1. **DL = ML'nin alt kÃ¼mesi** âœ“
2. **ANN = Artificial Neural Network** âœ“
3. **Otomatik feature extraction** âœ“
4. **3 Layer: Input, Hidden, Output** âœ“
5. **Backpropagation = Training algoritmasÄ±** âœ“
6. **GPU = DL'nin yÃ¼kseliÅŸi** âœ“
7. **CNN â†’ Images** âœ“
8. **Transformers â†’ Text (en yeni)** âœ“

### KarÅŸÄ±laÅŸtÄ±rmalar:
- ML â†’ Manuel features
- DL â†’ **Otomatik features**
- Traditional NN â†’ Sequential
- DL â†’ **Parallel computation**

### Mimariler:
- **Images:** CNN
- **Text:** Transformers > LSTM > RNN
- **Audio:** RNN, LSTM, Transformers
- **Generative:** GANs, Diffusion, Transformers

---

## ğŸ“‹ KONTROL LÄ°STESÄ°

- [ ] DL nedir, ML ile farkÄ±?
- [ ] ANN nedir?
- [ ] 3 layer tÃ¼rÃ¼?
- [ ] Neuron, Weight, Bias, Activation function?
- [ ] Otomatik feature extraction?
- [ ] Backpropagation ne iÅŸe yarar?
- [ ] GPU neden Ã¶nemli?
- [ ] Hangi veri tipi iÃ§in hangi mimari?
- [ ] Digit recognition Ã¶rneÄŸi?

**Hepsine EVET!**