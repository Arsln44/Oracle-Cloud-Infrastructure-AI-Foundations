# ğŸ´ FLASHCARDS - Supervised Learning: Regression

## TEMEL KAVRAMLAR

### Kart 1
**Ã–n YÃ¼z:** Supervised Learning output tÃ¼rÃ¼ne gÃ¶re 2 yÃ¶nteme ayrÄ±lÄ±r. Bunlar nelerdir?
**Arka YÃ¼z:** 
1. **Regression:** Output continuous (sÃ¼rekli) olduÄŸunda
2. **Classification:** Output categorical (kategorik) olduÄŸunda

---

### Kart 2
**Ã–n YÃ¼z:** Regression ne zaman kullanÄ±lÄ±r? Ã–rnek ver.
**Arka YÃ¼z:** 
**Ne zaman:** Output **continuous (sÃ¼rekli sayÄ±sal)** olduÄŸunda

**Ã–rnekler:**
- House price: $250,000
- Temperature: 25.5Â°C
- Age: 30 years
- Stock price: $150.75

---

### Kart 3
**Ã–n YÃ¼z:** Classification ne zaman kullanÄ±lÄ±r? Ã–rnek ver.
**Arka YÃ¼z:** 
**Ne zaman:** Output **categorical (kategori/sÄ±nÄ±f)** olduÄŸunda

**Ã–rnekler:**
- Spam: Yes/No
- Cancer: Malignant/Benign
- Sentiment: Positive/Negative/Neutral
- Animal: Cat/Dog

---

## LINEAR REGRESSION

### Kart 4
**Ã–n YÃ¼z:** Linear Regression denklemi nedir? Terimleri aÃ§Ä±kla.
**Arka YÃ¼z:** 
```
f(x) = w Ã— x + b
```

- **f(x) veya y:** Output/Prediction (Tahmin)
- **x:** Input (Girdi)
- **w:** Weight/Slope (AÄŸÄ±rlÄ±k/EÄŸim)
- **b:** Bias/Y-intercept (Sapma/Y-kesiÅŸim)

---

### Kart 5
**Ã–n YÃ¼z:** Linear Regression'da w (weight) ne iÅŸe yarar?
**Arka YÃ¼z:** 
**w = Slope (EÄŸim)**

**AnlamÄ±:** Output'un input'a gÃ¶re deÄŸiÅŸim oranÄ±

**House price Ã¶rneÄŸi:**
w = 200 â†’ Her 1 sq ft artÄ±ÅŸta $200 artÄ±ÅŸ

**Etkisi:**
- w â†‘ â†’ Ã‡izgi daha dik â†—
- w â†“ â†’ Ã‡izgi daha yatÄ±k â†’

---

### Kart 6
**Ã–n YÃ¼z:** Linear Regression'da b (bias) ne iÅŸe yarar?
**Arka YÃ¼z:** 
**b = Y-intercept (Y-kesiÅŸim noktasÄ±)**

**AnlamÄ±:** Input = 0 olduÄŸunda output deÄŸeri

**Etkisi:**
- b â†‘ â†’ Ã‡izgi yukarÄ± kayar â†‘
- b â†“ â†’ Ã‡izgi aÅŸaÄŸÄ± kayar â†“

---

### Kart 7
**Ã–n YÃ¼z:** Linear Regression'da optimal w ve b nasÄ±l bulunur?
**Arka YÃ¼z:** 
**Iteratively (TekrarlÄ±) ayarlama:**

1. Ä°lk w ve b deÄŸerleri ile baÅŸla
2. Tahmin yap: Å· = wÃ—x + b
3. Loss hesapla: (Å· - y)Â²
4. w ve b'yi ayarla (loss azalacak ÅŸekilde)
5. Loss minimum olana kadar tekrar et

---

## VERÄ° TERÄ°MLERÄ°

### Kart 8
**Ã–n YÃ¼z:** Independent Feature (BaÄŸÄ±msÄ±z Ã–zellik) nedir?
**Arka YÃ¼z:** 
**TanÄ±m:** DiÄŸer Ã¶zelliklere baÄŸlÄ± olmayan, **input** olan Ã¶zellik

**BaÅŸka adlarÄ±:** Input feature, X

**House price Ã¶rneÄŸi:** House Size (Ev bÃ¼yÃ¼klÃ¼ÄŸÃ¼)

**HatÄ±rlama:** Independent = SEBEP = INPUT

---

### Kart 9
**Ã–n YÃ¼z:** Dependent Feature (BaÄŸÄ±mlÄ± Ã–zellik) nedir?
**Arka YÃ¼z:** 
**TanÄ±m:** DiÄŸer Ã¶zelliklere **baÄŸlÄ±** olan, **output** olan Ã¶zellik

**BaÅŸka adlarÄ±:** Output label, Y

**House price Ã¶rneÄŸi:** Price (Fiyat) - Size'a BAÄLI

**HatÄ±rlama:** Dependent = SONUÃ‡ = OUTPUT

---

### Kart 10
**Ã–n YÃ¼z:** Training Example (EÄŸitim Ã–rneÄŸi) / Tuple nedir?
**Arka YÃ¼z:** 
**TanÄ±m:** Tek bir satÄ±r veri (Input + Output)

**House price Ã¶rneÄŸi:**
(1000 sq ft, $200,000) â† Bu bir training example/tuple

---

### Kart 11
**Ã–n YÃ¼z:** Training Data Set nedir?
**Arka YÃ¼z:** 
**TanÄ±m:** TÃ¼m training example'larÄ±n (tuple'larÄ±n) toplamÄ±

**KullanÄ±m:** Model oluÅŸturmak iÃ§in kullanÄ±lan veri seti

---

### Kart 12
**Ã–n YÃ¼z:** Scatter Plot neden kullanÄ±lÄ±r?
**Arka YÃ¼z:** 
**AmaÃ§:** Input ve output arasÄ±ndaki iliÅŸkiyi gÃ¶rselleÅŸtirmek

**FaydasÄ±:**
- Pattern'i gÃ¶rmek
- Ä°liÅŸkiyi anlamak
- Ã‡izgi uydurma iÃ§in

**Ã–rnek:** House Size vs Price scatter plot â†’ Pozitif korelasyon gÃ¶rÃ¼lÃ¼r

---

## HATA VE KAYIP

### Kart 13
**Ã–n YÃ¼z:** Error (Hata) nasÄ±l hesaplanÄ±r?
**Arka YÃ¼z:** 
```
Error = Predicted Value - Actual Value
Error = Å· - y
```

**Ã–rnek:**
- Actual Price (y): $250,000
- Predicted Price (Å·): $230,000
- Error: -$20,000

---

### Kart 14
**Ã–n YÃ¼z:** Loss (KayÄ±p) nedir?
**Arka YÃ¼z:** 
**TanÄ±m:** KÃ¶tÃ¼ tahmin iÃ§in ceza (penalty)

**Kurallar:**
- Perfect prediction â†’ Loss = 0
- Bad prediction â†’ Loss yÃ¼ksek

**AmaÃ§:** Loss'u minimize etmek

---

### Kart 15
**Ã–n YÃ¼z:** Squared Loss nasÄ±l hesaplanÄ±r ve neden kullanÄ±lÄ±r?
**Arka YÃ¼z:** 
**Hesaplama:**
```
Squared Loss = (Predicted - Actual)Â²
Squared Loss = (Å· - y)Â²
```

**Neden kare alÄ±nÄ±r:**
1. Negatif deÄŸerleri pozitif yapar
2. BÃ¼yÃ¼k hatalarÄ± daha fazla cezalandÄ±rÄ±r
3. Matematiksel olarak optimize edilmesi kolay

---

### Kart 16
**Ã–n YÃ¼z:** Loss = 0 ne zaman olur?
**Arka YÃ¼z:** 
**KoÅŸul:** Predicted = Actual olduÄŸunda

```
If Å· = y
Then Loss = (Å· - y)Â² = 0Â² = 0
```

**GerÃ§ekte:** Perfect prediction nadirdir, goal loss'u minimize etmektir.

---

## SUPERVISED LEARNING UYGULAMALARI

### Kart 17
**Ã–n YÃ¼z:** House Price Prediction'da input ve output nedir? Hangi tÃ¼r?
**Arka YÃ¼z:** 
**Input:** House size (square feet)
**Output:** Price (dolar)
**TÃ¼r:** **Regression** (Ã§Ã¼nkÃ¼ output continuous)

---

### Kart 18
**Ã–n YÃ¼z:** Cancer Detection'da input ve output nedir? Hangi tÃ¼r?
**Arka YÃ¼z:** 
**Input:** Medical details (TÄ±bbi detaylar)
**Output:** Malignant or not (KÃ¶tÃ¼ huylu mu deÄŸil mi)
**TÃ¼r:** **Classification** (Ã§Ã¼nkÃ¼ output categorical)

---

### Kart 19
**Ã–n YÃ¼z:** Sentiment Analysis'te input ve output nedir? Hangi tÃ¼r?
**Arka YÃ¼z:** 
**Input:** Customer reviews (MÃ¼ÅŸteri yorumlarÄ±)
**Output:** Positive, Negative, or Neutral
**TÃ¼r:** **Classification** (Ã§Ã¼nkÃ¼ output categorical)

---

### Kart 20
**Ã–n YÃ¼z:** Stock Price Prediction'da input ve output nedir? Hangi tÃ¼r?
**Arka YÃ¼z:** 
**Input:** Opening price, closing price, volume traded
**Output:** Stock price
**TÃ¼r:** **Regression** (Ã§Ã¼nkÃ¼ output continuous)

---

## Ã–ÄRETMEN-Ã–ÄRENCÄ° ANALOJÄ°SÄ°

### Kart 21
**Ã–n YÃ¼z:** Supervised Learning'i Ã¶ÄŸretmen-Ã¶ÄŸrenci analojisi ile aÃ§Ä±kla.
**Arka YÃ¼z:** 
**Teacher (Ã–ÄŸretmen):** Past outcomes = Labels
**Student (Ã–ÄŸrenci):** Model
**Learning (Ã–ÄŸrenme):** Input-output iliÅŸkisini Ã¶ÄŸrenme

Model, geÃ§miÅŸ sonuÃ§lardan (labeled data) Ã¶ÄŸrenir, tÄ±pkÄ± Ã¶ÄŸretmenin Ã¶ÄŸrenciye Ã¶ÄŸretmesi gibi.

---

## LINEAR REGRESSION SÃœRECÄ°

### Kart 22
**Ã–n YÃ¼z:** Linear Regression training sÃ¼recinin 6 adÄ±mÄ±nÄ± sÄ±rala.
**Arka YÃ¼z:** 
1. **Data Collection:** Input + Output topla
2. **Visualization:** Scatter plot ile pattern gÃ¶r
3. **Model Definition:** f(x) = wÃ—x + b
4. **Training:** w ve b'yi iteratif ayarla
5. **Trained Model:** Optimal w ve b bulundu
6. **Prediction:** Yeni input â†’ Tahmin

---

### Kart 23
**Ã–n YÃ¼z:** Model training'de iterasyon (iteration) ne demek?
**Arka YÃ¼z:** 
**TanÄ±m:** TekrarlÄ±, dÃ¶ngÃ¼sel sÃ¼reÃ§

**SÃ¼reÃ§:**
1. Predict (Tahmin yap)
2. Calculate Loss (KayÄ±p hesapla)
3. Adjust w and b (AÄŸÄ±rlÄ±k ve bias'Ä± ayarla)
4. Repeat (Tekrarla)

**Ne zaman durur:** Loss minimum olduÄŸunda

---

## KARÅILAÅTIRMALAR

### Kart 24
**Ã–n YÃ¼z:** Regression vs Classification - Temel fark?
**Arka YÃ¼z:** 
**Regression:**
- Output: Continuous (SayÄ±sal)
- Ã–rnek: Price ($250,000)

**Classification:**
- Output: Categorical (Kategori)
- Ã–rnek: Spam (Yes/No)

**HatÄ±rlama:** Regression = Numbers, Classification = Categories

---

### Kart 25
**Ã–n YÃ¼z:** Independent vs Dependent feature farkÄ±? House price Ã¶rneÄŸi.
**Arka YÃ¼z:** 
**Independent (BaÄŸÄ±msÄ±z):**
- Sebep, Input, X
- Ã–rnek: House Size

**Dependent (BaÄŸÄ±mlÄ±):**
- SonuÃ§, Output, Y
- Ã–rnek: Price (size'a baÄŸlÄ±!)

**Ä°liÅŸki:** Price DEPENDS ON Size

---

### Kart 26
**Ã–n YÃ¼z:** Error vs Loss farkÄ±?
**Arka YÃ¼z:** 
**Error:**
- Fark: Å· - y
- Pozitif veya negatif olabilir

**Loss:**
- Hata iÃ§in ceza
- Her zaman pozitif: (Å· - y)Â²
- Minimize edilmeli

---

## MATEMATÄ°KSEL Ä°LÄ°ÅKÄ°LER

### Kart 27
**Ã–n YÃ¼z:** w artarsa Ã§izgi nasÄ±l deÄŸiÅŸir? b artarsa?
**Arka YÃ¼z:** 
**w (slope) artar:**
- Ã‡izgi daha **dik** olur â†—
- Daha bÃ¼yÃ¼k eÄŸim

**b (bias) artar:**
- Ã‡izgi **yukarÄ±** kayar â†‘
- Paralel hareket

---

### Kart 28
**Ã–n YÃ¼z:** House price prediction'da w = 200 ne anlama gelir?
**Arka YÃ¼z:** 
**AnlamÄ±:** Her 1 square foot artÄ±ÅŸta, price $200 artar

**Matematiksel:**
- Slope (eÄŸim) = DeÄŸiÅŸim oranÄ±
- w = Î”Price / Î”Size = 200

---

## Ã–RNEKLER

### Kart 29
**Ã–n YÃ¼z:** House size 1,100 sq ft ise ve Ã§izgi denklemimiz f(x) = 200x + 50,000 ise, price tahmini nedir?
**Arka YÃ¼z:** 
```
f(1100) = 200 Ã— 1100 + 50,000
f(1100) = 220,000 + 50,000
f(1100) = $270,000
```

**Predicted Price: $270,000**

---

### Kart 30
**Ã–n YÃ¼z:** Actual price $250,000, predicted price $230,000. Error, squared loss ve interpretation?
**Arka YÃ¼z:** 
**Error:** 
Å· - y = $230,000 - $250,000 = -$20,000

**Squared Loss:**
(-20,000)Â² = 400,000,000

**Interpretation:** Model $20,000 dÃ¼ÅŸÃ¼k tahmin yaptÄ± (underestimated)

---

## Ã–ZEL DURUMLAR

### Kart 31
**Ã–n YÃ¼z:** Linear Regression'da "best fitting line" nasÄ±l bulunur?
**Arka YÃ¼z:** 
**YÃ¶ntem:** w ve b'yi iteratif ayarlayarak squared loss'u minimize etme

**SÃ¼reÃ§:**
- BirÃ§ok w ve b kombinasyonu denenmiÅŸ gibi
- Her kombinasyon iÃ§in loss hesaplanÄ±r
- En dÃ¼ÅŸÃ¼k loss veren = Best fitting line

---

### Kart 32
**Ã–n YÃ¼z:** Supervised Learning'de "mapping" ne demek?
**Arka YÃ¼z:** 
**Mapping:** Input ve output arasÄ±ndaki iliÅŸki/fonksiyon

**Matematiksel:** f: X â†’ Y

**House price:** 
- X (size) â†’ Y (price) mapping'i Ã¶ÄŸrenilir
- f(size) = price

---

### Kart 33
**Ã–n YÃ¼z:** Linear Regression hangi supervised learning alt tÃ¼rÃ¼dÃ¼r?
**Arka YÃ¼z:** 
**Alt TÃ¼r:** **Regression**

**Ã‡Ã¼nkÃ¼:**
- Output continuous
- DoÄŸrusal (linear) bir iliÅŸki varsayar
- f(x) = wÃ—x + b denklemi kullanÄ±r

---

### Kart 34
**Ã–n YÃ¼z:** Bir modelin "trained" olmasÄ± ne demek?
**Arka YÃ¼z:** 
**AnlamÄ±:** Optimal w ve b deÄŸerleri bulundu

**SÃ¼reÃ§ tamamlandÄ±:**
- Training data kullanÄ±ldÄ±
- Loss minimize edildi
- Model kullanÄ±ma hazÄ±r

**ArtÄ±k:** Yeni input â†’ Prediction yapabilir

---

## PRATIK UYGULAMALAR

### Kart 35
**Ã–n YÃ¼z:** Hangi problemler regression, hangileri classification? Listeden ayÄ±r: House price, Email spam, Stock price, Sentiment, Age prediction
**Arka YÃ¼z:** 
**Regression (Continuous):**
- House price â†’ SayÄ±sal
- Stock price â†’ SayÄ±sal
- Age prediction â†’ SayÄ±sal

**Classification (Categorical):**
- Email spam â†’ Yes/No
- Sentiment â†’ Pos/Neg/Neu

---

### Kart 36
**Ã–n YÃ¼z:** Training data set'iniz: [(1000, 200K), (1500, 300K), (2000, 400K)]. Independent ve dependent feature'lar?
**Arka YÃ¼z:** 
**Format:** (House Size, Price)

**Independent Feature (X):** 
- House Size: 1000, 1500, 2000

**Dependent Feature (Y):**
- Price: 200K, 300K, 400K

**Training Examples:** 3 tane

---

## Ä°LERÄ° SEVIYE

### Kart 37
**Ã–n YÃ¼z:** Loss function olarak baÅŸka ne kullanÄ±labilir? Squared loss'un avantajÄ±?
**Arka YÃ¼z:** 
**Alternatifler:**
- Absolute loss: |Å· - y|
- Huber loss: Kombinasyon

**Squared Loss AvantajlarÄ±:**
1. Her yerde tÃ¼revlenebilir (differentiable)
2. BÃ¼yÃ¼k hatalarÄ± cezalandÄ±rÄ±r
3. Tek global minimum var
4. Matematiksel olarak kolay

---

### Kart 38
**Ã–n YÃ¼z:** Linear Regression'Ä±n limitasyonu nedir?
**Arka YÃ¼z:** 
**Ana Limitasyon:** Sadece **linear (doÄŸrusal)** iliÅŸkileri modelleyebilir

**Sorun:** GerÃ§ek dÃ¼nyada birÃ§ok iliÅŸki non-linear

**Ã‡Ã¶zÃ¼m:** Polynomial regression, neural networks vb.

---

### Kart 39
**Ã–n YÃ¼z:** Multiple features olursa linear regression denklemi nasÄ±l olur?
**Arka YÃ¼z:** 
**Tek feature:**
f(x) = w Ã— x + b

**Multiple features:**
f(x) = wâ‚Ã—xâ‚ + wâ‚‚Ã—xâ‚‚ + ... + wâ‚™Ã—xâ‚™ + b

**House price Ã¶rneÄŸi:**
- xâ‚ = Size
- xâ‚‚ = Bedrooms
- xâ‚ƒ = Age
â†’ f(x) = wâ‚Ã—size + wâ‚‚Ã—bedrooms + wâ‚ƒÃ—age + b

---

### Kart 40
**Ã–n YÃ¼z:** Supervised Learning'de "labeled data" neden kritik?
**Arka YÃ¼z:** 
**Neden kritik:**
- Model, featuresâ†’labels iliÅŸkisini Ã¶ÄŸrenir
- Labels olmadan supervised learning yapÄ±lamaz
- Labels = "doÄŸru cevaplar" = Ã¶ÄŸretmen

**Analoji:** SÄ±navda cevap anahtarÄ± olmadan nasÄ±l Ã¶ÄŸrenilir?

---

## ğŸ“ Ã‡alÄ±ÅŸma Stratejisi

**Ã–ncelik SÄ±rasÄ±:**
â­â­â­ YÃ¼ksek: Kart 1-7, 13-16, 22, 24-25, 29-30
â­â­ Orta: Kart 8-12, 17-21, 23, 26-28, 31-36
â­ DÃ¼ÅŸÃ¼k: Kart 37-40 (ileri seviye)

**GÃ¼nlÃ¼k Plan:**
- GÃ¼n 1: Temel kavramlar (1-16)
- GÃ¼n 2: Uygulamalar + SÃ¼reÃ§ (17-28)
- GÃ¼n 3: Ã–rnekler + Ä°leri (29-40)

**Ä°pucu:** Regression vs Classification farkÄ±nÄ± Ã§ok iyi bilin!