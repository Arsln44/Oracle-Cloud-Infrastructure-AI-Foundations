# ğŸ“š GÃœN 2: REINFORCEMENT LEARNING - DetaylÄ± Ã‡alÄ±ÅŸma Notu

## ğŸ¯ ModÃ¼l Ã–zeti
Bu modÃ¼l Reinforcement Learning'in tanÄ±mÄ±nÄ±, terimlerini, gÃ¼nlÃ¼k hayattan Ã¶rneklerini ve robotic arm training sÃ¼recini aÃ§Ä±klÄ±yor.

---

## ğŸ• KÃ–PEK ANALOJÄ°SÄ° (Basit AÃ§Ä±klama)

**Reinforcement Learning = KÃ¶peÄŸe hÃ¼ner Ã¶ÄŸretmek gibi**

**SÃ¼reÃ§:**
1. KÃ¶pek bir ÅŸey yapar
2. DoÄŸru yaparsa â†’ **Ã–dÃ¼l** (treat, Ã¶vgÃ¼)
3. YanlÄ±ÅŸ yaparsa â†’ **Ceza** (uyarÄ±)
4. Zamanla â†’ Ã–dÃ¼l almak iÃ§in doÄŸru hareketleri Ã¶ÄŸrenir

**ğŸ’¡ AynÄ± prensip machine learning'de de kullanÄ±lÄ±r!**

---

## ğŸ“– REINFORCEMENT LEARNING TANIMI

### Resmi TanÄ±m
**Reinforcement Learning (RL):** Agent'Ä±n **environment** ile etkileÅŸimden Ã¶ÄŸrenmesini saÄŸlayan ML tÃ¼rÃ¼

**Ã–zellikler:**
- **Feedback:** Rewards (Ã¶dÃ¼ller) veya Penalties (cezalar)
- **NO Labeled Data:** Etiketli veri YOK!
- **Learning:** Deneme-yanÄ±lma ile

**ğŸ’¡ Supervised'dan farkÄ±: Labeled data yok, feedback var!**

---

## ğŸ’¼ GÃœNLÃœK HAYATTAN Ã–RNEKLER

### 1. Autonomous Vehicles (Otonom AraÃ§lar) ğŸš—

**KullanÄ±m:**
- Self-driving cars (Tesla, Waymo)
- Autonomous drones

**Ne Ã–ÄŸrenir:**
- GerÃ§ek zamanlÄ± kararlar
- Sensor data'ya gÃ¶re
- Trafik koÅŸullarÄ±na gÃ¶re
- GÃ¼venlik Ã¶ncelikli

**RL RolÃ¼:** Trial-error ile en iyi sÃ¼rÃ¼ÅŸ stratejisini Ã¶ÄŸrenir

---

### 2. Smart Home Devices (AkÄ±llÄ± Ev CihazlarÄ±) ğŸ 

**Ã–rnekler:**
- Alexa
- Google Assistant
- Siri

**RL KullanÄ±mÄ±:**
- Natural language processing iyileÅŸtirme
- KullanÄ±cÄ±nÄ±n konuÅŸma pattern'lerine adaptasyon
- Tercihleri Ã¶ÄŸrenme

**NasÄ±l:** KullanÄ±cÄ± etkileÅŸimlerinden feedback alÄ±r, geliÅŸir

---

### 3. Industrial Automation (EndÃ¼striyel Otomasyon) ğŸ­

**KullanÄ±m:**
- Manufacturing (Ãœretim)
- Production processes

**AmaÃ§:**
- Robot performansÄ±nÄ± optimize etme
- Kontrol sistemlerini iyileÅŸtirme

**SonuÃ§:**
- âœ… Artan verimlilik
- âœ… Azalan servis maliyeti

---

### 4. Gaming and Entertainment (Oyun ve EÄŸlence) ğŸ®

**KullanÄ±m:**
- Video games
- Virtual reality
- Interactive entertainment

**Ne Yapar:**
- Zeki ve zorlayÄ±cÄ± AI rakipler oluÅŸturur
- Oyuncu etkileÅŸimlerinden Ã¶ÄŸrenir
- Oyun ilerledikÃ§e **daha zor** hale gelir

**Ã–rnek:** AlphaGo (Go oyununu Ã¶ÄŸrendi ve dÃ¼nya ÅŸampiyonunu yendi)

---

## ğŸ”‘ REINFORCEMENT LEARNING TERÄ°MLERÄ°

### 1. AGENT (Ajan)

**TanÄ±m:** Ã–ÄŸrenen veya karar veren varlÄ±k

**Ã–zellikleri:**
- Environment ile etkileÅŸir
- Actions (hareketler) yapar
- Feedback'den Ã¶ÄŸrenir

**Ã–rnekler:**
- Self-driving car â†’ Car ve onun zekaasÄ±
- Dog training â†’ KÃ¶pek
- Robotic arm â†’ Robot kol
- Game AI â†’ Oyun karakteri

**ğŸ’¡ Agent = Ã–ÄŸrenen taraf**

---

### 2. ENVIRONMENT (Ã‡evre)

**TanÄ±m:** Agent'Ä±n etkileÅŸimde bulunduÄŸu dÄ±ÅŸ sistem

**Ã–zellikleri:**
- Agent'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± "dÃ¼nya"
- Agent'Ä±n hareketlerine feedback verir

**Ã–rnekler:**
- Self-driving car â†’ Road ve Ã§evresi
- Dog training â†’ EÄŸitim alanÄ±
- Robotic arm â†’ Warehouse (depo)
- Game â†’ Oyun dÃ¼nyasÄ±

**ğŸ’¡ Environment = Agent'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± alan**

---

### 3. STATE (Durum)

**TanÄ±m:** Environment'Ä±n belirli bir andaki mevcut durumunu temsil eder

**Ã–zellikleri:**
- Agent'Ä±n karar vermesi iÃ§in gerekli bilgiyi iÃ§erir
- Zamana gÃ¶re deÄŸiÅŸir

**Ã–rnekler:**
- Self-driving car â†’ KameranÄ±n o anda gÃ¶rdÃ¼ÄŸÃ¼ (yol, trafik vb.)
- Robotic arm â†’ Kolun pozisyonu, eÅŸyanÄ±n konumu
- Chess game â†’ SatranÃ§ tahtasÄ±nÄ±n mevcut durumu

**ğŸ’¡ State = "Åu anda ne oluyor?"**

---

### 4. ACTION (Hareket)

**TanÄ±m:** Agent'Ä±n belirli bir state'te yapabileceÄŸi olasÄ± hareketler

**Ã–zellikleri:**
- Environment'Ä± etkiler
- Future state'leri etkiler

**Ã–rnekler:**
- Self-driving car â†’ Drive left, drive right, keep straight
- Dog â†’ Sit, roll, pick up ball
- Robotic arm â†’ Pick item, move left/right, place item
- Chess â†’ TaÅŸÄ± hareket ettir

**ğŸ’¡ Action = Agent'Ä±n yapabilecekleri**

---

### 5. POLICY (Politika)

**TanÄ±m:** Agent'Ä±n hangi state'te hangi action'Ä± alacaÄŸÄ±na karar verme stratejisi

**BaÅŸka TanÄ±mlar:**
- **"Agent'Ä±n beyni"** (brain of the agent)
- State â†’ Action mapping
- Agent'Ä±n davranÄ±ÅŸÄ±nÄ± tanÄ±mlar

**Ã–rnekler:**
- Self-driving car â†’ "KÄ±rmÄ±zÄ± Ä±ÅŸÄ±kta dur, yeÅŸilde geÃ§" stratejisi
- Chess â†’ "Veziri koruma" stratejisi

**Ã–ÄŸrenme SonrasÄ±:**
```
BirÃ§ok deneme â†’ Feedback â†’ Policy Ã¶ÄŸrenilir
```

**ğŸ’¡ Policy = "Ne zaman ne yapmalÄ±?" stratejisi**

---

### 6. REWARD (Ã–dÃ¼l) ve PENALTY (Ceza)

**Reward:**
- **Pozitif** feedback
- DoÄŸru hareket yapÄ±ldÄ±ÄŸÄ±nda verilir
- Agent'Ä± o hareketi tekrarlamaya teÅŸvik eder

**Penalty:**
- **Negatif** feedback
- YanlÄ±ÅŸ hareket yapÄ±ldÄ±ÄŸÄ±nda verilir
- Agent'Ä± o hareketten kaÃ§Ä±nmaya teÅŸvik eder

**Ã–rnekler:**

| Durum | Reward | Penalty |
|-------|--------|---------|
| **Self-driving car** | GÃ¼venli sÃ¼rÃ¼ÅŸ, hedefe varma | Kaza, trafik ihlali |
| **Dog training** | Treat, Ã¶vgÃ¼ | UyarÄ±, kÄ±zmak |
| **Robotic arm** | DoÄŸru yere koyma | EÅŸyayÄ± dÃ¼ÅŸÃ¼rme, hasar |
| **Game** | Skor, level geÃ§me | Can kaybÄ±, game over |

**ğŸ’¡ Reward/Penalty = Feedback mekanizmasÄ±**

---

### 7. OPTIMAL POLICY (Optimal Politika)

**TanÄ±m:** Agent'a **en Ã§ok reward** kazandÄ±ran policy

**AmaÃ§:** RL algoritmasÄ±nÄ±n hedefi optimal policy'yi bulmak

**NasÄ±l Bulunur:**
- Ã‡ok deneme (training iterations)
- Algoritmalar: **Q-Learning**, **Deep Q-Learning**
- Trial-error sÃ¼reci

**SÃ¼reÃ§:**
```
Random Policy â†’ Training â†’ Learning â†’ Better Policy â†’ ... â†’ Optimal Policy
```

**ğŸ’¡ Optimal Policy = En iyi strateji**

---

## ğŸš— Ã–RNEK 1: SELF-DRIVING CAR

### Problem
**AmaÃ§:** Otonom aracÄ± yolda sÃ¼rmeyi ve hedefe varmayÄ± Ã¶ÄŸretmek

### RL Terimleriyle

**Agent:** Car ve onun zekaasÄ± (steering intelligence)

**Environment:** Road ve Ã§evresi

**State:** KameranÄ±n o anda gÃ¶rdÃ¼ÄŸÃ¼
- Yol durumu
- Trafik
- Ä°ÅŸaretler
- DiÄŸer araÃ§lar

**Actions:**
- Drive **left** (Sola sÃ¼r)
- Drive **right** (SaÄŸa sÃ¼r)
- Keep **straight** (DÃ¼z git)

**Policy:** "Bu gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶rÃ¼nce ÅŸu hareketi yap" stratejisi
- Ã–rnek: "KÄ±rmÄ±zÄ± Ä±ÅŸÄ±k â†’ Dur"

**Rewards:**
- GÃ¼venli sÃ¼rÃ¼ÅŸ
- Trafik kurallarÄ±na uyma
- Hedefe varma

**Penalties:**
- Kaza
- Trafik ihlali
- Yoldan Ã§Ä±kma

### Ã–ÄŸrenme SÃ¼reci

1. **Ä°lk Durum:** Rastgele hareketler
2. **Deneme:** FarklÄ± action'lar dener
3. **Feedback:** Reward/Penalty alÄ±r
4. **Ã–ÄŸrenme:** Ä°yi action'larÄ± Ã¶nceliklendirir
5. **Ä°terasyon:** Ã‡ok tekrar
6. **SonuÃ§:** Optimal policy (en iyi sÃ¼rÃ¼ÅŸ stratejisi)

**ğŸ’¡ YÃ¼zlerce/binlerce kez yolda gittikten sonra Ã¶ÄŸrenir**

---

## ğŸ¤– Ã–RNEK 2: ROBOTIC ARM (Warehouse)

### Problem
**AmaÃ§:** Robot kolunu warehouse'da eÅŸyalarÄ± verimli ve doÄŸru yerleÅŸtirmeyi Ã¶ÄŸretmek

---

## ğŸ”„ ROBOTIC ARM TRAINING SÃœRECÄ° (6 ADIM)

### AdÄ±m 1: SET ENVIRONMENT (Ã‡evreyi Ayarla)

**Ä°Ã§erir:**
- Robotic arm (Robot kol)
- Warehouse layout (Depo dÃ¼zeni)
- Goods to be placed (YerleÅŸtirilecek eÅŸyalar)
- Target locations (Hedef konumlar)

---

### AdÄ±m 2: DEFINE STATE REPRESENTATIONS (State'i TanÄ±mla)

**State Ä°Ã§eriÄŸi:**
- Robot kolun **pozisyonu** (position)
- Robot kolun **oryantasyonu** (orientation)
- AlÄ±nacak eÅŸyanÄ±n **konumu**
- Hedef konumlarÄ±n **pozisyonlarÄ±**

**ğŸ’¡ State = "Åu anda her ÅŸey nerede?"**

---

### AdÄ±m 3: DEFINE ACTION SPACE (Action'larÄ± TanÄ±mla)

**Possible Actions:**
- Pick up item (EÅŸyayÄ± al)
- Move left (Sola hareket et)
- Move right (SaÄŸa hareket et)
- Move forward (Ä°leri git)
- Move backward (Geri git)
- Place item (EÅŸyayÄ± bÄ±rak)
- Rotate (DÃ¶ndÃ¼r)

**ğŸ’¡ Action Space = Agent'Ä±n yapabilecekleri seti**

---

### AdÄ±m 4: DECIDE REWARDS AND PENALTIES (Ã–dÃ¼l/Ceza Belirle)

**Rewards (+):**
- âœ… EÅŸyayÄ± **doÄŸru yere** koyma
- âœ… **Verimli** hareket
- âœ… **HÄ±zlÄ±** tamamlama

**Penalties (-):**
- âŒ EÅŸyayÄ± **dÃ¼ÅŸÃ¼rme**
- âŒ EÅŸyaya **zarar** verme
- âŒ YanlÄ±ÅŸ yere koyma
- âŒ **YavaÅŸ** hareket

---

### AdÄ±m 5: TRAINING (EÄŸitim)

**Ä°lk Durum:**
- Robot **random state**'te baÅŸlar
- Rastgele action'lar dener (**exploration**)

**SÃ¼reÃ§:**
1. Action yap
2. Reward/Penalty gÃ¶zlemle
3. Ã–ÄŸren: Hangi action â†’ YÃ¼ksek reward
4. Ã–nceliklendirme: Ä°yi action'larÄ± tercih et
5. KaÃ§Ä±nma: KÃ¶tÃ¼ action'lardan kaÃ§Ä±n

**Exploration â†’ Exploitation:**
- **Exploration:** Yeni action'lar dene (ilk aÅŸama)
- **Exploitation:** Ã–ÄŸrenilen iyi action'larÄ± kullan (sonraki aÅŸama)

---

### AdÄ±m 6: MULTIPLE ITERATIONS (Ã‡oklu Ä°terasyon)

**SÃ¼reÃ§:**
```
Ä°terasyon 1 â†’ Ã–ÄŸrenme â†’ Better Strategy
Ä°terasyon 2 â†’ Ã–ÄŸrenme â†’ Better Strategy
...
Ä°terasyon N â†’ Optimal Strategy
```

**SonuÃ§:** Robot kol verimli pick-and-place stratejisi Ã¶ÄŸrenir

---

## ğŸ¯ REINFORCEMENT LEARNING = OPTIMAL POLICY BULMA

### SÃ¼reÃ§ Ã–zeti

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. BAÅLANGIÃ‡                          â”‚
â”‚  Agent â†’ Random actions                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. EXPLORATÄ°ON                        â”‚
â”‚  FarklÄ± action'lar dene                â”‚
â”‚  Reward/Penalty gÃ¶zlemle               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. LEARNING                           â”‚
â”‚  Ä°yi action'larÄ± Ã¶nceliklendir         â”‚
â”‚  KÃ¶tÃ¼ action'lardan kaÃ§Ä±n              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Ä°TERASYON                          â”‚
â”‚  Ã‡ok kez tekrarla                      â”‚
â”‚  Policy geliÅŸir                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. OPTIMAL POLICY                     â”‚
â”‚  En iyi strateji bulundu!              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ ANAHTAR KELÄ°MELER

### Temel Terimler
- âœ… **Reinforcement Learning:** Trial-error ile Ã¶ÄŸrenme
- âœ… **Agent:** Ã–ÄŸrenen varlÄ±k
- âœ… **Environment:** Ã‡evre, dÃ¼nya
- âœ… **State:** Mevcut durum
- âœ… **Action:** Hareket
- âœ… **Policy:** Strateji (stateâ†’action mapping)
- âœ… **Reward:** Ã–dÃ¼l (pozitif feedback)
- âœ… **Penalty:** Ceza (negatif feedback)
- âœ… **Optimal Policy:** En iyi strateji

### SÃ¼reÃ§ Terimleri
- âœ… **Exploration:** Yeni action'larÄ± deneme
- âœ… **Exploitation:** Ã–ÄŸrenilen iyi action'larÄ± kullanma
- âœ… **Training Iterations:** EÄŸitim tekrarlarÄ±
- âœ… **Feedback:** Geri bildirim
- âœ… **Trial-Error:** Deneme-yanÄ±lma

### Algoritmalar
- âœ… **Q-Learning:** RL algoritmasÄ±
- âœ… **Deep Q-Learning:** Deep learning + RL

---

## ğŸ’¡ Ã–NEMLÄ° NOTLAR

### 1. RL vs Supervised vs Unsupervised

| Ã–zellik | Supervised | Unsupervised | **Reinforcement** |
|---------|------------|--------------|-------------------|
| **Veri** | Labeled | Unlabeled | **Feedback** |
| **Ã–ÄŸrenme** | Examples'tan | Pattern'lerden | **Trial-error'dan** |
| **Feedback** | Yok | Yok | **VAR (Reward/Penalty)** |
| **Ã–rnek** | Classification | Clustering | **Game, Robot** |

**ğŸ’¡ RL'nin farkÄ±: Feedback var ama labeled data yok!**

---

### 2. Policy = Agent'Ä±n Beyni

**"Policy is the brain of the agent"**

- State gÃ¶rÃ¼r â†’ Policy karar verir â†’ Action yapar
- TÃ¼m Ã¶ÄŸrenme policy'ye kaydedilir
- Optimal policy = En iyi beyin

---

### 3. Exploration vs Exploitation

**Exploration (KeÅŸif):**
- Yeni action'lar dene
- Bilinmeyeni Ã¶ÄŸren
- Ä°lk aÅŸamada gerekli

**Exploitation (SÃ¶mÃ¼rme):**
- Ã–ÄŸrenilen iyi action'larÄ± kullan
- Reward'Ä± maksimize et
- Sonraki aÅŸamada

**Trade-off:** Ã‡ok exploration â†’ YavaÅŸ, Az exploration â†’ KÃ¶tÃ¼ policy

---

### 4. GÃ¼nlÃ¼k Hayatta Her Yerde

RL bizim farkÄ±nda olmadan hayatÄ±mÄ±zda:
- Netflix Ã¶nerileri
- Google Assistant
- Tesla autopilot
- Video game AI'lar
- Fabrika robotlarÄ±

---

## ğŸ¯ SINAV Ä°Ã‡Ä°N KRÄ°TÄ°K

### Mutlaka Bilin:
1. **Agent:** Ã–ÄŸrenen âœ“
2. **Environment:** Ã‡evre âœ“
3. **State:** Mevcut durum âœ“
4. **Action:** Hareket âœ“
5. **Policy:** Strateji (Stateâ†’Action) âœ“
6. **Reward:** Pozitif feedback âœ“
7. **Penalty:** Negatif feedback âœ“
8. **Optimal Policy:** En iyi strateji âœ“
9. **KÃ¶pek analojisi** âœ“
10. **Labeled data YOK, feedback VAR** âœ“

### Ã–rnekler:
- Self-driving car
- Robotic arm (warehouse)
- Gaming AI
- Smart home devices

---

## ğŸ“‹ KONTROL LÄ°STESÄ°

- [ ] RL nedir?
- [ ] Agent, Environment, State, Action, Policy tanÄ±mlarÄ±?
- [ ] Reward vs Penalty?
- [ ] Optimal policy nasÄ±l bulunur?
- [ ] Self-driving car Ã¶rneÄŸindeki terimler?
- [ ] Robotic arm 6 adÄ±mÄ±?
- [ ] Exploration vs Exploitation?
- [ ] RL vs Supervised vs Unsupervised?
- [ ] Policy = Brain?
- [ ] GÃ¼nlÃ¼k hayat Ã¶rnekleri?

**Hepsine EVET!**